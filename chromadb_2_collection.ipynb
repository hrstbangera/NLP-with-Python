{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4Ora6me9xww31E4ZSKnTh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79ba0d504d27487d8ff47eea57f03827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e60098bf7584b358fad21f05b32a210",
              "IPY_MODEL_c5d69f44d70e4d869d3a4f3c17fda17e",
              "IPY_MODEL_242e7ea14c58405aaadf6ae11430bb2c"
            ],
            "layout": "IPY_MODEL_4ceedb5e1f8e4514877344bc8b896cf5"
          }
        },
        "0e60098bf7584b358fad21f05b32a210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872db544951b418c97c8e54dcf55227d",
            "placeholder": "​",
            "style": "IPY_MODEL_4032032bb1b84b1c82dca73d95750019",
            "value": "modules.json: 100%"
          }
        },
        "c5d69f44d70e4d869d3a4f3c17fda17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09cd64564c94483e93d9f6c3e45a6d18",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ac1ba03a2684a05b1bc8b3bafbc1428",
            "value": 349
          }
        },
        "242e7ea14c58405aaadf6ae11430bb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27dde907d1340a6a010798bd5b25120",
            "placeholder": "​",
            "style": "IPY_MODEL_85ab6329be5941d3a20cd688af80665e",
            "value": " 349/349 [00:00&lt;00:00, 6.24kB/s]"
          }
        },
        "4ceedb5e1f8e4514877344bc8b896cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872db544951b418c97c8e54dcf55227d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4032032bb1b84b1c82dca73d95750019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09cd64564c94483e93d9f6c3e45a6d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac1ba03a2684a05b1bc8b3bafbc1428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c27dde907d1340a6a010798bd5b25120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ab6329be5941d3a20cd688af80665e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849af6fa5b7a48dc8b40f0339759c1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67bb13751704453fa71d62e49939a6e4",
              "IPY_MODEL_64cefa224fa04659939d67f7e130f854",
              "IPY_MODEL_2a1d5e63d3664a49b99617f726658e46"
            ],
            "layout": "IPY_MODEL_d355b60e229943afab5d7fa60821fe11"
          }
        },
        "67bb13751704453fa71d62e49939a6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362df7a5b52c47d28a9249f19594fb0a",
            "placeholder": "​",
            "style": "IPY_MODEL_2c10f36b526a4ddb89429596e4272893",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "64cefa224fa04659939d67f7e130f854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c10f556e0f534e1d835e3751799f1b19",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b7b3d41379e480bae9f9e5cf917a559",
            "value": 116
          }
        },
        "2a1d5e63d3664a49b99617f726658e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7958ec3710984641b1977005ec6da953",
            "placeholder": "​",
            "style": "IPY_MODEL_3f95510f5d5647d8ab21cd1ba3991c4c",
            "value": " 116/116 [00:00&lt;00:00, 5.53kB/s]"
          }
        },
        "d355b60e229943afab5d7fa60821fe11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362df7a5b52c47d28a9249f19594fb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c10f36b526a4ddb89429596e4272893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c10f556e0f534e1d835e3751799f1b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7b3d41379e480bae9f9e5cf917a559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7958ec3710984641b1977005ec6da953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f95510f5d5647d8ab21cd1ba3991c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b120e5a7a9744eeac283d1b61f17c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be73b390737140f5bc740418fc913acb",
              "IPY_MODEL_f585e31ed64f42a4ac1d8ffea55438c8",
              "IPY_MODEL_7268a8db6e8f4fba9e46b7d3e56386e5"
            ],
            "layout": "IPY_MODEL_072f034c19e240d794dbd428f74ecb57"
          }
        },
        "be73b390737140f5bc740418fc913acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b455ca9443ca4d2a804186580d114cca",
            "placeholder": "​",
            "style": "IPY_MODEL_640ae6c7c855464da804d0a4c61aed0d",
            "value": "README.md: 100%"
          }
        },
        "f585e31ed64f42a4ac1d8ffea55438c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1e851d7630a467dace92a535c767153",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e0cd2ce4fcd4e1184de302c521fec76",
            "value": 10659
          }
        },
        "7268a8db6e8f4fba9e46b7d3e56386e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57e610da4d64e7a8b4fe5f0e26bd6bc",
            "placeholder": "​",
            "style": "IPY_MODEL_3225cbe41f954aa5a02f8de9e10487cf",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 286kB/s]"
          }
        },
        "072f034c19e240d794dbd428f74ecb57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b455ca9443ca4d2a804186580d114cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640ae6c7c855464da804d0a4c61aed0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1e851d7630a467dace92a535c767153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e0cd2ce4fcd4e1184de302c521fec76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d57e610da4d64e7a8b4fe5f0e26bd6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3225cbe41f954aa5a02f8de9e10487cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe447556e82a45fcb5e78efd308d892f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cd333b5d862429889f6f8eb9ee4d87b",
              "IPY_MODEL_59158271d8da46ab9df8bdb1b6a39b52",
              "IPY_MODEL_ddfe8e88db66495cabc11f1f097cfa44"
            ],
            "layout": "IPY_MODEL_d093aee0ba2f4bdbafccb68258bec3d4"
          }
        },
        "3cd333b5d862429889f6f8eb9ee4d87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f571c54d11a446a9e8262ba084f5520",
            "placeholder": "​",
            "style": "IPY_MODEL_57afa24f61cf476d8ee7e02bd7b74a1a",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "59158271d8da46ab9df8bdb1b6a39b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f81979b904b24238b081bf3adcef427f",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1c660c52b33409db7db4a2641a0c4f0",
            "value": 53
          }
        },
        "ddfe8e88db66495cabc11f1f097cfa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f76b455d09334fd0a6bf462dacd9273b",
            "placeholder": "​",
            "style": "IPY_MODEL_a201ad1375e342cbb86924a522f8317f",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.24kB/s]"
          }
        },
        "d093aee0ba2f4bdbafccb68258bec3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f571c54d11a446a9e8262ba084f5520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57afa24f61cf476d8ee7e02bd7b74a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f81979b904b24238b081bf3adcef427f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c660c52b33409db7db4a2641a0c4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f76b455d09334fd0a6bf462dacd9273b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a201ad1375e342cbb86924a522f8317f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6b61f2859e74dbcb6aaa613fed56936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5cbab74ef0e4bbe9a57e4094d0cfdba",
              "IPY_MODEL_55530b5e117b4d74a4aae9882073282b",
              "IPY_MODEL_52ef1ac179084134b9abb3e4e9dede8c"
            ],
            "layout": "IPY_MODEL_f92f151327f74795894949b70330dc07"
          }
        },
        "d5cbab74ef0e4bbe9a57e4094d0cfdba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c30a0bc44f094bc2bb66d35ab007583b",
            "placeholder": "​",
            "style": "IPY_MODEL_4283615efd494bbda1e4db975257b7a9",
            "value": "config.json: 100%"
          }
        },
        "55530b5e117b4d74a4aae9882073282b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b971142ee9444c71bb6536d92725afb6",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a017f8760c94fb78b148903078d1543",
            "value": 612
          }
        },
        "52ef1ac179084134b9abb3e4e9dede8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24fd300ab2854b1d97968fb82200d71e",
            "placeholder": "​",
            "style": "IPY_MODEL_b8575326e9d841c691488d64949821ae",
            "value": " 612/612 [00:00&lt;00:00, 27.2kB/s]"
          }
        },
        "f92f151327f74795894949b70330dc07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30a0bc44f094bc2bb66d35ab007583b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4283615efd494bbda1e4db975257b7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b971142ee9444c71bb6536d92725afb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a017f8760c94fb78b148903078d1543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24fd300ab2854b1d97968fb82200d71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8575326e9d841c691488d64949821ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d8fc6c45b84f0aa57d96d7f73a99e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae72f38eba4b4d9281cf6adb33c956c7",
              "IPY_MODEL_0970e866e5024550a3c95e61dbee8e5d",
              "IPY_MODEL_1c7b0ea6d8b642238317f194ef8640e0"
            ],
            "layout": "IPY_MODEL_87806d37311b4bafbc3623724429baf8"
          }
        },
        "ae72f38eba4b4d9281cf6adb33c956c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a996eb4beb1f41359136f6c7ef5405af",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a4e9ebbc264e0b90a3f2999b857031",
            "value": "model.safetensors: 100%"
          }
        },
        "0970e866e5024550a3c95e61dbee8e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2d76ac20feb4d829b5a8a3989f19c57",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d2daf7f59314eaba4be82126ba82b4b",
            "value": 90868376
          }
        },
        "1c7b0ea6d8b642238317f194ef8640e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6364770696aa42ceaf531e4c257baa6a",
            "placeholder": "​",
            "style": "IPY_MODEL_28086436958f4b78a1c549c45f72e225",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 172MB/s]"
          }
        },
        "87806d37311b4bafbc3623724429baf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a996eb4beb1f41359136f6c7ef5405af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a4e9ebbc264e0b90a3f2999b857031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2d76ac20feb4d829b5a8a3989f19c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d2daf7f59314eaba4be82126ba82b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6364770696aa42ceaf531e4c257baa6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28086436958f4b78a1c549c45f72e225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c54c60661a46a2a827eb43cedd1364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1d8b62151894e0f91c3cc46febcfca9",
              "IPY_MODEL_768ab2193ba94c0da0140ba596a37064",
              "IPY_MODEL_a1bf04591d5a457487d6ccfa3950c99b"
            ],
            "layout": "IPY_MODEL_a1b54c1882934f60a969df15a393a98a"
          }
        },
        "f1d8b62151894e0f91c3cc46febcfca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8b7f03a9334d11826d30ca2cdd8008",
            "placeholder": "​",
            "style": "IPY_MODEL_a720d127864643bfbb4846a4c85a552d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "768ab2193ba94c0da0140ba596a37064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ad1f627f1849118291cb90f4b27f36",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1bf5ac59b444483921798bacfda8c50",
            "value": 350
          }
        },
        "a1bf04591d5a457487d6ccfa3950c99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7c1fe3f13845de8eeeef6d96097e6b",
            "placeholder": "​",
            "style": "IPY_MODEL_3e53f10c77be4d588d5e682b39115873",
            "value": " 350/350 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "a1b54c1882934f60a969df15a393a98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8b7f03a9334d11826d30ca2cdd8008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a720d127864643bfbb4846a4c85a552d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15ad1f627f1849118291cb90f4b27f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bf5ac59b444483921798bacfda8c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e7c1fe3f13845de8eeeef6d96097e6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e53f10c77be4d588d5e682b39115873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc35d8489bfa49aa8a0c2af76b0fb43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7ad6a17356e4fbeb95def0df999e59e",
              "IPY_MODEL_83bc7400895d422f8ba2e661ad1a6fe8",
              "IPY_MODEL_44ab3c3bd66943af8fdd660912a540d5"
            ],
            "layout": "IPY_MODEL_a410c1399f984fbe87607721c2ea2ab5"
          }
        },
        "b7ad6a17356e4fbeb95def0df999e59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001c5981eebc4716ac98ab248f8340f7",
            "placeholder": "​",
            "style": "IPY_MODEL_8ce7704efc2644e387e081c969bab30b",
            "value": "vocab.txt: 100%"
          }
        },
        "83bc7400895d422f8ba2e661ad1a6fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b46a539f0a49e585fd1005215cab49",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72e28211f9564f668ccf0c33f460a322",
            "value": 231508
          }
        },
        "44ab3c3bd66943af8fdd660912a540d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693251ad607444f9b76288ad66da489c",
            "placeholder": "​",
            "style": "IPY_MODEL_8e2f7a64735e4d518e12c8db4574472d",
            "value": " 232k/232k [00:00&lt;00:00, 3.65MB/s]"
          }
        },
        "a410c1399f984fbe87607721c2ea2ab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "001c5981eebc4716ac98ab248f8340f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ce7704efc2644e387e081c969bab30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77b46a539f0a49e585fd1005215cab49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e28211f9564f668ccf0c33f460a322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "693251ad607444f9b76288ad66da489c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2f7a64735e4d518e12c8db4574472d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fa9d92ea4df4526b9bd9d697c027d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f14babe0486342899bae0f93f555baef",
              "IPY_MODEL_4345098b10a24d21bcd3df5e247f3d4f",
              "IPY_MODEL_5c35d6f2b44b43dd984b364bbb79d142"
            ],
            "layout": "IPY_MODEL_94dea0c6204147879621283cbbd6d3b2"
          }
        },
        "f14babe0486342899bae0f93f555baef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1074d45f7fc4a9ea4bfb6e1cf75c604",
            "placeholder": "​",
            "style": "IPY_MODEL_73adde55ceb84e27b2ed32661e30c3d6",
            "value": "tokenizer.json: 100%"
          }
        },
        "4345098b10a24d21bcd3df5e247f3d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f16168a878e24d61be0cc48553082dcf",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cb53eb8dff045799697ef4b9f8c7759",
            "value": 466247
          }
        },
        "5c35d6f2b44b43dd984b364bbb79d142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85a1abf5a0d64c3695709586ba8542bf",
            "placeholder": "​",
            "style": "IPY_MODEL_b8652858a0764d0fbeff6e7e2895dcdb",
            "value": " 466k/466k [00:00&lt;00:00, 2.36MB/s]"
          }
        },
        "94dea0c6204147879621283cbbd6d3b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1074d45f7fc4a9ea4bfb6e1cf75c604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73adde55ceb84e27b2ed32661e30c3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f16168a878e24d61be0cc48553082dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb53eb8dff045799697ef4b9f8c7759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85a1abf5a0d64c3695709586ba8542bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8652858a0764d0fbeff6e7e2895dcdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "887caf2cf4454267a3ff0c04bbcaaf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c02f87c868c347e1a2d81cafb1418557",
              "IPY_MODEL_e5bda095f3ca4c7a83bfaa071b2e6d2d",
              "IPY_MODEL_59f79152ce73488bbe3e1415f181d65f"
            ],
            "layout": "IPY_MODEL_4f4b14e3c43c40879c7698586b2e0c13"
          }
        },
        "c02f87c868c347e1a2d81cafb1418557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691f349215f0463f9bc74eb6a9eda175",
            "placeholder": "​",
            "style": "IPY_MODEL_bf57b5315c01436c87c3b91d99b33e7d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e5bda095f3ca4c7a83bfaa071b2e6d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23436b836cff49a485f962c7817a8cb1",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c72261a1f744b5298dec410f1a47321",
            "value": 112
          }
        },
        "59f79152ce73488bbe3e1415f181d65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44ff0fd980f44acb3e46358989caea9",
            "placeholder": "​",
            "style": "IPY_MODEL_a0984b7f529b45a08a091fa51bf1c81e",
            "value": " 112/112 [00:00&lt;00:00, 3.04kB/s]"
          }
        },
        "4f4b14e3c43c40879c7698586b2e0c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691f349215f0463f9bc74eb6a9eda175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf57b5315c01436c87c3b91d99b33e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23436b836cff49a485f962c7817a8cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c72261a1f744b5298dec410f1a47321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b44ff0fd980f44acb3e46358989caea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0984b7f529b45a08a091fa51bf1c81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcaf7dcfbf774e50967df158bf334c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15204003a9bf4fa8bc861eaf7b5f7268",
              "IPY_MODEL_aa0311bb08cf44698fdc8c2fa0c5fd73",
              "IPY_MODEL_ca78cbc1cc134972b767a6a0fc46bf5b"
            ],
            "layout": "IPY_MODEL_7306c94284c84e0e96e0cf8b5d48aa34"
          }
        },
        "15204003a9bf4fa8bc861eaf7b5f7268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a512d73e90fe48a3b6d93de6adf3bffa",
            "placeholder": "​",
            "style": "IPY_MODEL_acfa4831230241b2a0d57a6f19c94bd3",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "aa0311bb08cf44698fdc8c2fa0c5fd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e56a71b2a5c243f09c231a53d0bd3646",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9095d2f525c943018e203f3538b020c7",
            "value": 190
          }
        },
        "ca78cbc1cc134972b767a6a0fc46bf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce8e1701c38a4593a380bb8e28f62071",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a7f96f3226415abfb6117c11a00a7c",
            "value": " 190/190 [00:00&lt;00:00, 9.23kB/s]"
          }
        },
        "7306c94284c84e0e96e0cf8b5d48aa34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a512d73e90fe48a3b6d93de6adf3bffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acfa4831230241b2a0d57a6f19c94bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e56a71b2a5c243f09c231a53d0bd3646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9095d2f525c943018e203f3538b020c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce8e1701c38a4593a380bb8e28f62071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a7f96f3226415abfb6117c11a00a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrstbangera/NLP-with-Python/blob/master/chromadb_2_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THQlesaHJJyP",
        "outputId": "18f4dc01-a067-4ea3-8571-0dfb2a1c0d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSCJLtlImIz5",
        "outputId": "4d603f0a-c26d-4d6d-eda2-050a3fb597cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Collecting chromadb<0.6.0,>=0.4.0 (from langchain-chroma)\n",
            "  Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<1,>=0.95.2 (from langchain-chroma)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.3,>=0.1.40 (from langchain-chroma)\n",
            "  Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (1.25.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.8.0)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.4.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.27.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.1.40->langchain-chroma)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3,>=0.1.40->langchain-chroma)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain-chroma) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.12.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.19.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.16.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=120a9148d37ea0bc7d6a4337f7ccc7ae6c1262327892efce6b7a310872a93751\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, ujson, python-multipart, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, httpcore, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, httpx, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-core, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.1.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-chroma-0.1.2 langchain-core-0.2.11 langsmith-0.1.83 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.1 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.6 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK1UFHsNmrWX",
        "outputId": "6fa4de6a-91b9-4416-ff38-8a32bb699790"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.6 (from langchain_community)\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.11)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.6->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (2.8.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (2.20.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-0.2.6 langchain-text-splitters-0.2.2 langchain_community-0.2.6 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI6N2-IoyVSU",
        "outputId": "7110dafb-c6d0-4ac6-f4cc-25785d7da1f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/290.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-text-splitters"
      ],
      "metadata": {
        "id": "aYUY6S6kBAv3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "moG2i1HQxLsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "# Set up the embedding function\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create or connect to a persistent Chroma client with local storage\n",
        "persistent_client = chromadb.PersistentClient(path=\"/content/sample_data/db\")\n",
        "\n",
        "collection_name = \"pdf_collection\"\n",
        "collection = persistent_client.get_or_create_collection(collection_name)\n",
        "\n",
        "# Function to load and split text from a PDF using PyPDFLoader\n",
        "# def load_text_from_pdf(pdf_path):\n",
        "#     loader = PyPDFLoader(pdf_path)\n",
        "#     pages = loader.load_and_split()\n",
        "#     text = \" \".join([page.page_content for page in pages])\n",
        "#     return text\n",
        "\n",
        "def load_text_from_pdf(pdf_path):\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load_and_split()\n",
        "    text = \" \".join([page.page_content for page in pages])\n",
        "    return text\n",
        "\n",
        "# Function to chunk text\n",
        "def chunk_text(text, chunk_size=500, chunk_overlap=50):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "# Paths to your PDF files\n",
        "pdf_paths = [\"/content/sample_data/105InvestmentPolicyStatement.pdf\", \"/content/sample_data/llama2_removed.pdf\"]\n",
        "\n",
        "# Extract text from PDFs, chunk them, and create document entries\n",
        "documents = []\n",
        "ids = []\n",
        "# for idx, pdf_path in enumerate(pdf_paths):\n",
        "#     text = load_text_from_pdf(pdf_path)\n",
        "#     chunks = chunk_text(text)\n",
        "#     documents.extend(chunks)\n",
        "#     ids.extend([f\"{idx+1}_{i}\" for i in range(len(chunks))])\n",
        "for pdf_path in pdf_paths:\n",
        "    filename = os.path.basename(pdf_path).replace(\".pdf\", \"\")\n",
        "    text = load_text_from_pdf(pdf_path)\n",
        "    chunks = chunk_text(text)\n",
        "    documents.extend(chunks)\n",
        "    ids.extend([f\"{filename}_{i}\" for i in range(len(chunks))])\n",
        "\n",
        "# Add documents to the collection\n",
        "collection.add(ids=ids, documents=documents)\n",
        "\n",
        "# Set up LangChain Chroma\n",
        "langchain_chroma = Chroma(\n",
        "    client=persistent_client,\n",
        "    collection_name=collection_name,\n",
        "    embedding_function=embedding_function,\n",
        ")\n",
        "\n",
        "# # Function to print the contents of the collection\n",
        "# def print_collection_contents():\n",
        "#     all_documents = collection.get()\n",
        "#     for doc in all_documents['documents']:\n",
        "#         print(doc)\n",
        "def print_collection_contents():\n",
        "    all_documents = collection.get()\n",
        "    for doc_id, doc_content in zip(all_documents['ids'], all_documents['documents']):\n",
        "        print(f\"Document ID {doc_id}: {doc_content}\")\n",
        "\n",
        "# Print the number of documents in the collection\n",
        "print(\"There are\", langchain_chroma._collection.count(), \"documents in the collection\")\n",
        "\n",
        "# Print the contents of the collection before update\n",
        "print(\"Contents before update:\")\n",
        "print_collection_contents()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "79ba0d504d27487d8ff47eea57f03827",
            "0e60098bf7584b358fad21f05b32a210",
            "c5d69f44d70e4d869d3a4f3c17fda17e",
            "242e7ea14c58405aaadf6ae11430bb2c",
            "4ceedb5e1f8e4514877344bc8b896cf5",
            "872db544951b418c97c8e54dcf55227d",
            "4032032bb1b84b1c82dca73d95750019",
            "09cd64564c94483e93d9f6c3e45a6d18",
            "9ac1ba03a2684a05b1bc8b3bafbc1428",
            "c27dde907d1340a6a010798bd5b25120",
            "85ab6329be5941d3a20cd688af80665e",
            "849af6fa5b7a48dc8b40f0339759c1b9",
            "67bb13751704453fa71d62e49939a6e4",
            "64cefa224fa04659939d67f7e130f854",
            "2a1d5e63d3664a49b99617f726658e46",
            "d355b60e229943afab5d7fa60821fe11",
            "362df7a5b52c47d28a9249f19594fb0a",
            "2c10f36b526a4ddb89429596e4272893",
            "c10f556e0f534e1d835e3751799f1b19",
            "2b7b3d41379e480bae9f9e5cf917a559",
            "7958ec3710984641b1977005ec6da953",
            "3f95510f5d5647d8ab21cd1ba3991c4c",
            "6b120e5a7a9744eeac283d1b61f17c55",
            "be73b390737140f5bc740418fc913acb",
            "f585e31ed64f42a4ac1d8ffea55438c8",
            "7268a8db6e8f4fba9e46b7d3e56386e5",
            "072f034c19e240d794dbd428f74ecb57",
            "b455ca9443ca4d2a804186580d114cca",
            "640ae6c7c855464da804d0a4c61aed0d",
            "e1e851d7630a467dace92a535c767153",
            "2e0cd2ce4fcd4e1184de302c521fec76",
            "d57e610da4d64e7a8b4fe5f0e26bd6bc",
            "3225cbe41f954aa5a02f8de9e10487cf",
            "fe447556e82a45fcb5e78efd308d892f",
            "3cd333b5d862429889f6f8eb9ee4d87b",
            "59158271d8da46ab9df8bdb1b6a39b52",
            "ddfe8e88db66495cabc11f1f097cfa44",
            "d093aee0ba2f4bdbafccb68258bec3d4",
            "2f571c54d11a446a9e8262ba084f5520",
            "57afa24f61cf476d8ee7e02bd7b74a1a",
            "f81979b904b24238b081bf3adcef427f",
            "b1c660c52b33409db7db4a2641a0c4f0",
            "f76b455d09334fd0a6bf462dacd9273b",
            "a201ad1375e342cbb86924a522f8317f",
            "d6b61f2859e74dbcb6aaa613fed56936",
            "d5cbab74ef0e4bbe9a57e4094d0cfdba",
            "55530b5e117b4d74a4aae9882073282b",
            "52ef1ac179084134b9abb3e4e9dede8c",
            "f92f151327f74795894949b70330dc07",
            "c30a0bc44f094bc2bb66d35ab007583b",
            "4283615efd494bbda1e4db975257b7a9",
            "b971142ee9444c71bb6536d92725afb6",
            "0a017f8760c94fb78b148903078d1543",
            "24fd300ab2854b1d97968fb82200d71e",
            "b8575326e9d841c691488d64949821ae",
            "10d8fc6c45b84f0aa57d96d7f73a99e2",
            "ae72f38eba4b4d9281cf6adb33c956c7",
            "0970e866e5024550a3c95e61dbee8e5d",
            "1c7b0ea6d8b642238317f194ef8640e0",
            "87806d37311b4bafbc3623724429baf8",
            "a996eb4beb1f41359136f6c7ef5405af",
            "c8a4e9ebbc264e0b90a3f2999b857031",
            "b2d76ac20feb4d829b5a8a3989f19c57",
            "1d2daf7f59314eaba4be82126ba82b4b",
            "6364770696aa42ceaf531e4c257baa6a",
            "28086436958f4b78a1c549c45f72e225",
            "56c54c60661a46a2a827eb43cedd1364",
            "f1d8b62151894e0f91c3cc46febcfca9",
            "768ab2193ba94c0da0140ba596a37064",
            "a1bf04591d5a457487d6ccfa3950c99b",
            "a1b54c1882934f60a969df15a393a98a",
            "ab8b7f03a9334d11826d30ca2cdd8008",
            "a720d127864643bfbb4846a4c85a552d",
            "15ad1f627f1849118291cb90f4b27f36",
            "c1bf5ac59b444483921798bacfda8c50",
            "5e7c1fe3f13845de8eeeef6d96097e6b",
            "3e53f10c77be4d588d5e682b39115873",
            "bc35d8489bfa49aa8a0c2af76b0fb43d",
            "b7ad6a17356e4fbeb95def0df999e59e",
            "83bc7400895d422f8ba2e661ad1a6fe8",
            "44ab3c3bd66943af8fdd660912a540d5",
            "a410c1399f984fbe87607721c2ea2ab5",
            "001c5981eebc4716ac98ab248f8340f7",
            "8ce7704efc2644e387e081c969bab30b",
            "77b46a539f0a49e585fd1005215cab49",
            "72e28211f9564f668ccf0c33f460a322",
            "693251ad607444f9b76288ad66da489c",
            "8e2f7a64735e4d518e12c8db4574472d",
            "5fa9d92ea4df4526b9bd9d697c027d38",
            "f14babe0486342899bae0f93f555baef",
            "4345098b10a24d21bcd3df5e247f3d4f",
            "5c35d6f2b44b43dd984b364bbb79d142",
            "94dea0c6204147879621283cbbd6d3b2",
            "e1074d45f7fc4a9ea4bfb6e1cf75c604",
            "73adde55ceb84e27b2ed32661e30c3d6",
            "f16168a878e24d61be0cc48553082dcf",
            "6cb53eb8dff045799697ef4b9f8c7759",
            "85a1abf5a0d64c3695709586ba8542bf",
            "b8652858a0764d0fbeff6e7e2895dcdb",
            "887caf2cf4454267a3ff0c04bbcaaf54",
            "c02f87c868c347e1a2d81cafb1418557",
            "e5bda095f3ca4c7a83bfaa071b2e6d2d",
            "59f79152ce73488bbe3e1415f181d65f",
            "4f4b14e3c43c40879c7698586b2e0c13",
            "691f349215f0463f9bc74eb6a9eda175",
            "bf57b5315c01436c87c3b91d99b33e7d",
            "23436b836cff49a485f962c7817a8cb1",
            "5c72261a1f744b5298dec410f1a47321",
            "b44ff0fd980f44acb3e46358989caea9",
            "a0984b7f529b45a08a091fa51bf1c81e",
            "bcaf7dcfbf774e50967df158bf334c75",
            "15204003a9bf4fa8bc861eaf7b5f7268",
            "aa0311bb08cf44698fdc8c2fa0c5fd73",
            "ca78cbc1cc134972b767a6a0fc46bf5b",
            "7306c94284c84e0e96e0cf8b5d48aa34",
            "a512d73e90fe48a3b6d93de6adf3bffa",
            "acfa4831230241b2a0d57a6f19c94bd3",
            "e56a71b2a5c243f09c231a53d0bd3646",
            "9095d2f525c943018e203f3538b020c7",
            "ce8e1701c38a4593a380bb8e28f62071",
            "e5a7f96f3226415abfb6117c11a00a7c"
          ]
        },
        "id": "tY9qFZEOpKoF",
        "outputId": "53522703-8447-4760-c8af-48918bff36af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79ba0d504d27487d8ff47eea57f03827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "849af6fa5b7a48dc8b40f0339759c1b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b120e5a7a9744eeac283d1b61f17c55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe447556e82a45fcb5e78efd308d892f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6b61f2859e74dbcb6aaa613fed56936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10d8fc6c45b84f0aa57d96d7f73a99e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c54c60661a46a2a827eb43cedd1364"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc35d8489bfa49aa8a0c2af76b0fb43d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fa9d92ea4df4526b9bd9d697c027d38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "887caf2cf4454267a3ff0c04bbcaaf54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcaf7dcfbf774e50967df158bf334c75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02<00:00, 33.4MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 99 documents in the collection\n",
            "Contents before update:\n",
            "Document ID 105InvestmentPolicyStatement_0: Section 1.05  \n",
            "Page 1 of 9 \n",
            " \n",
            "MURRAY STATE UNIVERSITY FOUNDATION, INC.  \n",
            "POLICY  \n",
            " \n",
            " \n",
            "SUBJECT:  Investment Policy Statement  \n",
            " \n",
            "DATE :  November 15, 2015  \n",
            " \n",
            "I. Purpose  \n",
            " \n",
            "Investments made  by the Murray  State  University  Foundation,  Inc. (“Foundation ”) are \n",
            "to be managed  in such a way that maximizes the  Foundation's  ability  to contribute  to \n",
            "the goals  of Murray  State  University  (“University ”).  The investment  policy statement\n",
            "Document ID 105InvestmentPolicyStatement_1: (“Policies”)  for the investment  of monies  and securities ( “Portfolio ”) owned  or under  \n",
            "the custodial  care of the Foundation  is established  by a Joint  Investments  Committee \n",
            "(“Joint Investment s Committee ”) with limited  authority being granted  to a sub -\n",
            "committee, Investment Committee, as defined in Section Three.   \n",
            " \n",
            "The purpose of this investment policy statement is to establish guidelines for the\n",
            "Document ID 105InvestmentPolicyStatement_10: investment po licies, and will be limited to P ortfolio changes of  10% or less of the \n",
            "Portfolio (or  sometimes referred to as Investment P ool), cumulatively, between \n",
            "regularly scheduled board meetings (i.e. if the investment pool is $90 million, then \n",
            "cumulative changes between board meetings shall be limited to $9 million).  If \n",
            "extraordinary circumstance s exist, and it is deemed by the Investment Committee\n",
            "Document ID 105InvestmentPolicyStatement_11: that Portfolio changes greater than 10% (cumulatively) should occur, then the Joint \n",
            "Investments Committee  shall be consulted by a conference call as soon as \n",
            "reasonably possible.  \n",
            " \n",
            "C. Portfolio  changes  made  between  board  meetings  by the Investment Committee  will \n",
            "be presented  to the Joint  Investments  Committee  and Board  of Trustees  at the \n",
            "next scheduled  board  meeting  for ratification of  all actions pursuant  to this policy.\n",
            "Document ID 105InvestmentPolicyStatement_12: D. In addition,  the Investment  Committee  does not have  the authority  to hire new \n",
            "investment  managers  between  board  meetings, change  existing  investment \n",
            "managers, or  change  overall  investment  policy,  but will have the ability  to make \n",
            "recommendations  regarding  new or existing  investment  managers  to the Joint \n",
            "Investments  Committee  at  the  next  board  meeting.     Changes  in  existing \n",
            "investment  managers,  the hiring  of new investment  managers, or  changes  in\n",
            "Document ID 105InvestmentPolicyStatement_13: investment  policy,  shall  be  conducted  by  the  Joint  Investments  Committee \n",
            "through  an agreed process  and approved  by the Board  of Trustees. Section 1.05  \n",
            "Page 3 of 9 \n",
            " \n",
            "E. The Investment  Committee  shall  in writing  direct  the President  of the Foundation \n",
            "to make  approved  changes  in the Portfolio  within  the parameters of these  \n",
            "guidelines.  \n",
            " \n",
            "IV. Investment Objective and Spending  Policy\n",
            "Document ID 105InvestmentPolicyStatement_14: IV. Investment Objective and Spending  Policy  \n",
            " \n",
            "A. The F oundation  is to invest  with the objective of preserving the long -term, real \n",
            "purchasing power of assets while providing a relatively predictable and growing \n",
            "stream of annual di stributions  (“Spending Rate”)  in support of the University .  \n",
            " \n",
            "B. For the purpose of making distributions, the F oundation shall make use of a total \n",
            "return based spending policy, meaning that it will fund distributions from net\n",
            "Document ID 105InvestmentPolicyStatement_15: investment income, net realized c apital gains, and proceeds from the sale of \n",
            "investments.  \n",
            " \n",
            "C. The distribution of F oundation  assets will be permitted to the extent that such \n",
            "distributions do not exceed a level that would erode the F oundation ’s real assets \n",
            "over time. The Joint Investments Committee will seek to reduce the variability of \n",
            "annual F oundation  distributions by factori ng past spending and Portfolio asset\n",
            "Document ID 105InvestmentPolicyStatement_16: values into its current spending decisions.  The Joint Investments Committee  will \n",
            "review spending assumptions annually upon a recommendation by the Foundation \n",
            "President for the purpose of deciding  the annual Spending Rate,  whether any \n",
            "changes therein necessitate amending the F oundation ’s spending policy, its target \n",
            "asset allocation, or both.  In addition, the Board of Trustees shall approve the annual \n",
            "Spending Rate upon a recommendation by the Foundation Presi dent and approval\n",
            "Document ID 105InvestmentPolicyStatement_17: by the Joint Investments Committee.  \n",
            " \n",
            "D. Periodic cash flow, either into or out of the Portfolio, will be used to better align \n",
            "the P ortfolio to the target asset allocation outlined in the Asse t Allocation Policy at \n",
            "Section V. A. herein.   \n",
            " \n",
            "V. Portfolio Investment Policies  \n",
            " \n",
            "A. Asset Allocation Policy  \n",
            " \n",
            "1. The Joint Investments Committee  recognizes that the strategic allocation of \n",
            "Portfolio assets across broadly -defined financial asset and sub -asset categories\n",
            "Document ID 105InvestmentPolicyStatement_18: with varying degrees of risk, return, and return correlation will be the most \n",
            "significant determinant of long -term investment returns and Portfolio asset \n",
            "value stability.   \n",
            " \n",
            "2. The Joint Investments Committee  expects that actual returns and return \n",
            "volatility may vary widely from expectations and retu rn objectives across short \n",
            "periods of time.  While the Joint Investments Committee  wishes to retain \n",
            "flexibility with respect to making periodic changes to the Portfolio’s asset\n",
            "Document ID 105InvestmentPolicyStatement_19: allocation, it expects to do so only in the event of material changes to the \n",
            "Foundation , to the assumptions underlying F oundation  spending policies, \n",
            "and/or to the capital markets and asset classes in which the Portfolio invests. Section 1.05  \n",
            "Page 4 of 9 \n",
            " \n",
            "3. Foundation  assets will be managed as a balanced portfolio comprised of two \n",
            "major components: an equity portion and a fixed income portion.  The expected\n",
            "Document ID 105InvestmentPolicyStatement_2: Foundation ’s investment Portfolio  in the areas that most influence investment returns \n",
            "and risks.  The investment policy statement also incorporates accountability standards \n",
            "that will be used for monitoring the progress of the Portfolio’s investment program and \n",
            "for evaluating t he contributions of the managers  hired on behalf of the F oundation  and \n",
            "its beneficiaries.  \n",
            " \n",
            "II. Role of the Joint Investment s Committee\n",
            "Document ID 105InvestmentPolicyStatement_20: role of F oundation  equity investments will be to maximize the long -term real \n",
            "growth of Portfolio assets, while the role of fixed income investments will be \n",
            "to generate current income, provide for more stabl e periodic returns, and \n",
            "provide some protection against a prolonged decline in the market value of \n",
            "Portfolio equity investments.  The Board of Trustees  will determine  the \n",
            "appropriate  mix between  equities  and fixed  income. The Board of  Trustees\n",
            "Document ID 105InvestmentPolicyStatement_21: may choose  to invest  up to 70%,  or more,  of available  funds  in equities . \n",
            "However,  the Board of Trustees  may also reduce  equity  exposure  to as low as  \n",
            "40%,  or less, when  they deem  it appropriate.  The remainder  will be invested  in \n",
            "fixed  income  securities,  including  cash reserves,  which  the Board of Trustees  \n",
            "may retain,  separate  from  the managers  from time  to time.  \n",
            " \n",
            "4. Cash investments will, under normal circumstances, only be considered as\n",
            "Document ID 105InvestmentPolicyStatement_22: temporary Portfolio holdings, and will be used for the Foundation ’s liquidity \n",
            "needs or to facilitate a planned program of dollar cost averaging into \n",
            "investments in either or both of t he equity and fixed income asset classes.  \n",
            " \n",
            "5. Outlined below are the long -term strategic asset allocation guidelines, \n",
            "determined by the Joint Investments Committee  to be the most appropriate, \n",
            "given the F oundation ’s long -term objectives and short -term constrai nts.\n",
            "Document ID 105InvestmentPolicyStatement_23: Portfolio assets will, under normal circumstances, be allocated across broad \n",
            "asset and sub -asset classes in accordance with the following guidelines:  \n",
            " \n",
            "Asset Class  Sub-Asset Class  Target Allocation  \n",
            "Equity    65% \n",
            " Domestic (U.S.)  39% \n",
            " International (Non -U.S.)  26% \n",
            "   \n",
            "Fixed Income   34% \n",
            " Investment Grade  34% \n",
            "   \n",
            "Real Estate  Real Estate Investment \n",
            "Trusts  1% \n",
            "   \n",
            "Cash   0% \n",
            " \n",
            "B. Diversification Policy\n",
            "Document ID 105InvestmentPolicyStatement_24: Cash   0% \n",
            " \n",
            "B. Diversification Policy  \n",
            " \n",
            "Diversification across and within asset classes is the primary means by which the \n",
            "Joint Investments Committee  expects the Portfolio to avoid undue risk of large \n",
            "losses over long time periods.  To protect the Portfolio against unfavorable \n",
            "outcomes within an  asset class due to the assumption of large risks, the Joint \n",
            "Investments Committee  will take reasonable precautions to avoid excessive\n",
            "Document ID 105InvestmentPolicyStatement_25: investment concentrations.  Specifically, the following guidelines will be in place: Section 1.05  \n",
            "Page 5 of 9 \n",
            " \n",
            "1. With the exception of fixed income investments explicitly guaranteed by the \n",
            "U.S. government, no single investment security shall represent more than 5% \n",
            "of total Portfolio assets.  \n",
            " \n",
            "2. With the exception of passively managed investment vehicles seeking to match \n",
            "the returns on a broadly diversifi ed market index, no single investment pool or\n",
            "Document ID 105InvestmentPolicyStatement_26: investment company (mutual fund) shall comprise more than 20% of total \n",
            "Portfolio assets.  \n",
            " \n",
            "C. Rebalancing Policies  \n",
            " \n",
            "It is expected that the Portfolio’s actual asset allocation will vary from its target \n",
            "asset allocation as a result of the varying periodic returns earned on its \n",
            "investments in different asset and sub -asset classes.  The Portfolio will be re -\n",
            "balanced to its  target normal asset allocation as follows :\n",
            "Document ID 105InvestmentPolicyStatement_27: 1. Utilize incoming cash flow (contributions) or outgoing money mo vements \n",
            "(disbursements) of the P ortfolio to realign the current weightings closer to  the \n",
            "target weightings for the P ortfolio.  \n",
            " \n",
            "2. The P ortfolio will be  reviewed quarterly  with the I nvestment Committee and \n",
            "President of the Foundation  to determine the deviation from target weightings. \n",
            "During each quarterly review, the following parameters will be applied:\n",
            "Document ID 105InvestmentPolicyStatement_28: a) If any asset class (equi ty or fixed income) withi n the P ortfolio is  +/ -5 \n",
            "percentage points from its target weighting,  the P ortfolio will be rebalanced.  \n",
            " \n",
            "b) If any fund within the P ortfolio has increased or decreased by greater than \n",
            "20% of its target weighting, the fund may be rebalanced.  \n",
            " \n",
            "3. The President of the Foundation or Controller  will provide the  investment \n",
            "manager s with quart erly fixed income statements in order to determine  possible \n",
            "Portfolio rebalancing.\n",
            "Document ID 105InvestmentPolicyStatement_29: Portfolio rebalancing.  \n",
            "  \n",
            "4. The investment manager s may provide  rebalancing recommendation s at any \n",
            "time.  \n",
            " \n",
            "5. The investment manager s shall act within a reasonable period of time to \n",
            "evaluate deviation from these ranges.  \n",
            " \n",
            "D. Policies Governing Investment Discretion and Authorized/Prohibited \n",
            "Transactions  \n",
            " \n",
            "1. The Joint Investments Committee authorizes the outside investment manager, \n",
            "to invest in equity securities as of October 13, 1995.\n",
            "Document ID 105InvestmentPolicyStatement_3: II. Role of the Joint Investment s Committee  \n",
            " \n",
            "The Joint Investment s Committee is comprised of  at least  three trustees of the \n",
            "Foundation, two members of the Board of Regents, and two members of the Murray \n",
            "State University Alumni Board of  Governors . The Joint Investments Committee is \n",
            "acting in a fiduciary capacity with respect to the Portfolio, and is accountable to the \n",
            "Board  of Trustees  for overseeing the investment of all assets included in the Portfolio.\n",
            "Document ID 105InvestmentPolicyStatement_30: 2. The Joint  Investments  Committee authorizes  the outside  investment  manager s \n",
            "to also invest  in fixed  income  accounts  as of June 10, 1998.  The policy Section 1.05  \n",
            "Page 6 of 9 \n",
            " \n",
            "is included  below in “Investment Guidelines for Fixed Income \n",
            "Managers.”  \n",
            "   \n",
            "3. The Joint  Investments  Committee  authorizes  the Investment  Committee  to \n",
            "make investments  of  excess  cash  not  being  invested  through  the  \n",
            "investment  manager s  as follows:\n",
            "Document ID 105InvestmentPolicyStatement_31: investment  manager s  as follows:  \n",
            " \n",
            "a. Cash  funds  available  for investments  shall,  whenever  possible,  be \n",
            "pooled  into amounts of $100,000 or more.  \n",
            " \n",
            "b. Cash  funds shall  be invested  for short -term periods  in non -speculative , \n",
            "liquid assets such as Treasury Securities, Certificates of Deposit , Money \n",
            "Market Funds, or other Government backed securities .  It may be \n",
            "necessary to use collateralization vehicles such as a letter of credit to\n",
            "Document ID 105InvestmentPolicyStatement_32: fully secure short -term, liquid investments.  \n",
            " \n",
            "c. A maximum  investment  of $250 ,000  shall  be held in any institution  at \n",
            "a given  time.    (Exception:   A local ly negotiated , fully secured \n",
            "arrangement  for the  investment  of checking  account  funds,  as permitted  \n",
            "by cash flow requirements.)  \n",
            " \n",
            "d. No investment  shall  be placed  with any institution  on the basis  of \n",
            "political  favor, friendship,  or influence  by any officials,  alumnus  or\n",
            "Document ID 105InvestmentPolicyStatement_33: friend  of the University. Competitive, safe,  and best bids shall be \n",
            "sought  for all funds  invested  by Foundation  officials.  \n",
            " \n",
            "e. Funds  in checking  accounts  will be invested  in negotiated  short -term \n",
            "certificates  of deposit,  prime  accounts,  money  market  accounts  or other  \n",
            "insured, interest  bearing  accounts.  \n",
            " \n",
            "4. The purchase  of real estate  shall be authorized by  the Investment Committee \n",
            "or Joint Investment  Committee.\n",
            "Document ID 105InvestmentPolicyStatement_34: or Joint Investment  Committee.  \n",
            " \n",
            "5. Pooled  investment  earnings,  including  realized  and unrealized  gains  and \n",
            "losses, shall  be pro-rated  to the individual  investment  accounts  in accordance  \n",
            "with the amount  of funds  invested.  This allocation  will be  made  based  on the \n",
            "market  value of  each fund's  principal  balance  at the beginning  of the quarter.  \n",
            " \n",
            "E. Investment  Guidelines  for Fixed  Income  Managers\n",
            "Document ID 105InvestmentPolicyStatement_35: 1. Investments will be mostly limited to marketable debt securities rated at the \n",
            "time of purchase within the four highest investment grade ratings (BBB, Baa or \n",
            "better) assigned by Moody's Investors Service, Inc. or Standard & Poor's \n",
            "Corporation or which, alth ough not rated by either agency, are deemed as being \n",
            "of investment quality equivalent.  \n",
            " \n",
            "2. Fixed  income  securities  return  expectations  are to exceed  the Bloomberg US\n",
            "Document ID 105InvestmentPolicyStatement_36: Aggregate Bond Index  or other  similar  index,  as deemed  acceptable  to the \n",
            "Joint Investments Committee  over one, three  and five years.  The Portfolio’s Section 1.05  \n",
            "Page 7 of 9 \n",
            " \n",
            "duration should be within a range of +/ - 20% of the duration of the  \n",
            "Index  \n",
            " \n",
            "3. Not more  than twenty  percent  (20%)  of the fixed  income portion of the \n",
            "Portfolio  may be invested  in any one  broadly  defined  industry,  regardless  of\n",
            "Document ID 105InvestmentPolicyStatement_37: the number  of individual  holdings. Not  more  than five percent  (5%)  of the \n",
            "fixed  income  portfolio  may be  invested  in any one corporate  issuer,  at cost,  \n",
            "specifically  excluding  U.S. Treasury,  GNMA, FNMA,  FHLB  and any other  \n",
            "government  sponsored  enterprise  securities.  (U.S. Treasury  and GNMA  also \n",
            "excluded  from  the 20% limit  above).  \n",
            " \n",
            "4. Up to 5.0% of  the assets in  the fixed income portion of the Portfolio may be\n",
            "Document ID 105InvestmentPolicyStatement_38: securities of  investment grade  foreign issuers, including emerging markets \n",
            "securities.    \n",
            " \n",
            "5. The fixed income portion of the Portfolio may include corporate securities, U.S. \n",
            "Government securities, zero coupon securities, mortgage -backed securities, \n",
            "commercial mortgage backed securities (CMBS), collateralized mortgage \n",
            "obligations,  asset backed securities, equipment trust certificates, taxable \n",
            "municipal bonds, preferred securities, and real estate investment trusts ( REITs ).\n",
            "Document ID 105InvestmentPolicyStatement_39: No more than twenty percent (20%) of the fixed income portion of the Portfolio \n",
            "may be invested in a combination of the following asset types: asset backed \n",
            "securities, equipment trust certificates, taxable municipal bonds, preferred \n",
            "securities, and real estate investment trusts.  \n",
            " \n",
            "6. In order  to ensure  overall  diversification  (maturity,  sector,  issuer,  quality,  etc.),  \n",
            "all the Foundation's  fixed  income  holdings  will be taken  into consideration\n",
            "Document ID 105InvestmentPolicyStatement_4: A. The Policies set forth the inve stment objectives, distribution policies, and \n",
            "investment guidelines that govern the activities of the Joint Investments Committee  \n",
            "and any other parties to whom the Joint Investments Committee  has delegated \n",
            "investment management responsibility for Portfolio  assets.  \n",
            " \n",
            "B. Quarterly investment management statements of the Foundation’s P ortfolio as \n",
            "prepared by our investment managers are sent to the Joint Investments Committee .\n",
            "Document ID 105InvestmentPolicyStatement_40: when making  investment  decisions.  \n",
            " \n",
            "7. Mutual funds and other types of commingled investment vehicles provide, \n",
            "under some circumstances, lower costs and better diversification than can be \n",
            "obtained with separately managed portfolios pursuing the same investment \n",
            "objectives. However, commingled in vestment funds cannot customize their \n",
            "investment policies and guidelines to the specific needs of individual clients.\n",
            "Document ID 105InvestmentPolicyStatement_41: Therefore, if the Foundation selects a mutual fund or other type of commingled \n",
            "vehicle for investment, either directly or through an inve stment management \n",
            "agreement, then the written guidelines and policies of the commingled fund or \n",
            "the prospectus and statement of additional information for the mutual fund, and \n",
            "any provisions set forth in any investment management agreement will replace \n",
            "this Policy Statement for these particular type of investments. The Manager or\n",
            "Document ID 105InvestmentPolicyStatement_42: other fund representative will provide a copy of the applicable commingled or \n",
            "mutual fund guidelines, policies, prospectus and other governing documents to \n",
            "the Foundation.  \n",
            " \n",
            "F. Other I nvestment Policies  \n",
            " \n",
            "Unless expressly authorized by the Joint Investments Committee , the Portfolio , \n",
            "the underlying funds,  and its investment managers are prohibited from: Section 1.05  \n",
            "Page 8 of 9 \n",
            " \n",
            "1. Purchasing securities on margin, or executing short sales.\n",
            "Document ID 105InvestmentPolicyStatement_43: 2. Pledging or hypothecating  securiti es, except for loans of securities that are fully \n",
            "collateralized within the mutual fund investment.  \n",
            " \n",
            "3. Purchasing or selling derivative securities for speculation or leverage.  \n",
            " \n",
            "4. Purchasing corporate bonds that are convertible to equity.  \n",
            " \n",
            "5. Purchasing highly levered mortgage securities, which for the purpose of this \n",
            "policy, are defined as inverse floating rate securities, interest or principal only \n",
            "strips, or any combination thereof.\n",
            "Document ID 105InvestmentPolicyStatement_44: strips, or any combination thereof.  \n",
            " \n",
            "6. Purchases of real estate, oil & gas properties, or other n atural resource related \n",
            "properties with the exception of REITs or marketable real estate securities.  \n",
            " \n",
            "7. Investments in limited partnerships.  \n",
            " \n",
            "8. Purchasing Repurchase Agreements, Senior Loans, Collater alized Debt \n",
            "Obligations, Collateralized Bond Obligations, Co llateralized Loan Obligations, \n",
            "Structured Investment Vehicles, Special Purpose Entity Obligations, swaps or\n",
            "Document ID 105InvestmentPolicyStatement_45: other derivative contracts.  \n",
            " \n",
            "9. Engaging in investment strategies that have the potential to amplify or distort \n",
            "the risk of loss beyond a level that is  reasonably expected given the objectives \n",
            "of their portfolios . \n",
            " \n",
            "VI. Monitoring Portfolio Investments and Performance  \n",
            " \n",
            "The Investment Committee and Joint Investments Committee  will monitor the \n",
            "Portfolio’s investment performance against the Portfolio’s stated investment\n",
            "Document ID 105InvestmentPolicyStatement_46: objectives. T he Investment Committee and Joint Investments Committee  will formally \n",
            "assess the Portfolio and the performance of its underlying investments as follows:  \n",
            " \n",
            "A. The Portfolio’s composite investment performance (net of fees) will be  judged \n",
            "against the following standards:  \n",
            " \n",
            "1. The Portfolio’s absolute long -term real return objective . \n",
            " \n",
            "2. A composite benchmark consisting of the following unmanaged market indices\n",
            "Document ID 105InvestmentPolicyStatement_47: weighted according to the expected target asset allocations stipulated by the \n",
            "Portfolio’s investment guidelines . \n",
            " \n",
            "a) U.S. Equity:  CRSP US Total Market Index  or a similar broad domestic \n",
            "equity index . \n",
            " \n",
            "b) Non-U.S. Equity:  FTSE Global All Cap ex US Index or a similar broad \n",
            "international equity index . Section 1.05  \n",
            "Page 9 of 9 \n",
            " \n",
            "c) Investment Grade Fixed Income:  Bloomberg US Aggregate Bond Index.  \n",
            " \n",
            "d) Real Estate Investment Trusts: MSCI US REIT Index .\n",
            "Document ID 105InvestmentPolicyStatement_48: e) Cash: Citigroup 3 -Month T -Bill Index . \n",
            " \n",
            "B. The performance of professional investment managers hired on behalf of the \n",
            "Portfolio will be judg ed against the following standards:  \n",
            " \n",
            "1. A market -based index appropriately selec ted or tailored to the managers’  \n",
            "agreed -upon investment objective and the normal investment characteristics of \n",
            "the managers’  portfolio . \n",
            " \n",
            "2. The performance of other investment manage rs having similar investment \n",
            "objectives .\n",
            "Document ID 105InvestmentPolicyStatement_49: objectives . \n",
            " \n",
            "C. In keeping with the Portfolio’s overall long -term financial objective, the Investment \n",
            "Committee and Joint Investments Committee  will evaluate Portfolio and manager \n",
            "performance over a suitably long -term investment horizon, generally across full \n",
            "market cycles or, at a minimum, on a rolling five -year basis.  \n",
            " \n",
            "D. Investment reports shall be provi ded by the investment managers  on a (fiscal) \n",
            "quarterly    basis or as more frequently requested by the Joint Investmen ts\n",
            "Document ID 105InvestmentPolicyStatement_5: C. The Joint Investments Committee  meets twice a year at  the regular Board meetings \n",
            "of the Foundation, and at such other times as deemed necessary.  The quarterly \n",
            "Investment R eport of invested funds is prepared by the Foundation staff and \n",
            "distributed to members of the Joint Investments Committee, the T reasurer,  and to \n",
            "the full Board of Trustees , including ex -officio members,  on a quarterly basis .\n",
            "Document ID 105InvestmentPolicyStatement_50: Committee.   Each investment manager is expected to be available to meet with the \n",
            "Joint Investments Committee and Board of Trustees at least twice per year to review \n",
            "Portfolio structure, strategy, and investment performance.  Additionally, the \n",
            "investmen t manager s will be available to the Investment Committee for quarterly \n",
            "conference calls and as needed by the President of the Foundation.       \n",
            " \n",
            " \n",
            " \n",
            "Revised:  April 23, 2022\n",
            "Document ID 105InvestmentPolicyStatement_6: D. The Policies for the F oundation  contained herein have been  formulated consistent \n",
            "with anticipated financial needs and in consideration of t he tolerance for assuming Section 1.05  \n",
            "Page 2 of 9 \n",
            " \n",
            "investment and financial risk, as reflected in the majority opinion of the Joint \n",
            "Investments Committee .     \n",
            " \n",
            "E. The Policies contained in this statement are intended to provide boundaries, where \n",
            "necessary, for ensuring that the Portfolio’s investments are man aged consistent\n",
            "Document ID 105InvestmentPolicyStatement_7: with the short -term and long -term financial goals of the Foundation .  At the same \n",
            "time, they are intended to provide for sufficient investment flexibility in the face of \n",
            "changes in capital market conditions and in the financial circumstance s of the  \n",
            "Foundation and  University . \n",
            " \n",
            "F. The Policies will be reviewed by the Joint Investments Committee and the Board \n",
            "of Trustees of the Foundation on an annual basis or more often as needed. Changes\n",
            "Document ID 105InvestmentPolicyStatement_8: may be made at their discretion and in consultation with t he investment manager s. \n",
            " \n",
            "III. Investment Committee Authority and Guidelines  \n",
            " \n",
            "A. The Investment Committee as provided for in Article 3, Section 3 of the Foundation  \n",
            "By-Laws, and as approved at the October 9,  2009  Board of Trustees meeting allows \n",
            "for a three member Investment Committee  (“Investment Committee”)  to make \n",
            "changes to the Foundation's Portfolio between regularly scheduled board meetings.\n",
            "Document ID 105InvestmentPolicyStatement_9: This policy ratifies the intent of the Foundation's By -Laws and pre vious actions by \n",
            "the Board of Trustees to grant limited authority to the Investment Committee to \n",
            "make specific changes to the P ortfolio between regularly scheduled board meetings \n",
            "in order to be efficient in our investment mana gement process and to maximize  \n",
            "Portfolio performance.  \n",
            " \n",
            "B. The Investment Committee will be required to adhere to the Foundation's existing\n",
            "Document ID llama2_removed_0: Llama 2 : Open Foundation and Fine-Tuned Chat Models\n",
            "Hugo Touvron∗Louis Martin†Kevin Stone†\n",
            "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
            "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
            "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
            "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
            "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
            "Document ID llama2_removed_1: Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
            "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
            "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
            "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
            "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
            "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
            "Document ID llama2_removed_10: canbenoisyduetolimitationsofthepromptset,subjectivity\n",
            "of the review guidelines, subjectivity of individual raters,\n",
            "and the inherent difficulty of comparing generations.\n",
            "Figure 2: Win-rate % for helpfulness and\n",
            "safety between commercial-licensed base-\n",
            "lines and Llama 2-Chat , according to GPT-\n",
            "4. Tocomplementthehumanevaluation,we\n",
            "used a more capable model, not subject to\n",
            "ourownguidance. Greenareaindicatesour\n",
            "modelisbetteraccordingtoGPT-4. Toremove\n",
            "ties, we used win/ (win+loss). The orders in\n",
            "Document ID llama2_removed_11: ties, we used win/ (win+loss). The orders in\n",
            "whichthemodelresponsesarepresentedto\n",
            "GPT-4arerandomlyswappedtoalleviatebias.\n",
            "1 Introduction\n",
            "Large Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\n",
            "complex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\n",
            "domains such as programming and creative writing. They enable interaction with humans through intuitive\n",
            "Document ID llama2_removed_12: chat interfaces, which has led to rapid and widespread adoption among the general public.\n",
            "ThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\n",
            "methodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\n",
            "followed by alignment with human preferences via techniques such as Reinforcement Learning with Human\n",
            "Feedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\n",
            "Document ID llama2_removed_13: limited the development of LLMs to a few players. There have been public releases of pretrained LLMs\n",
            "(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\n",
            "match the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\n",
            "(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\n",
            "Document ID llama2_removed_14: asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\n",
            "preferences, which greatly enhances their usability and safety. This step can require significant costs in\n",
            "computeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\n",
            "the community to advance AI alignment research.\n",
            "In this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\n",
            "Document ID llama2_removed_15: Llama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\n",
            "Llama 2-Chat models generally perform better than existing open-source models. They also appear to\n",
            "be on par with some of the closed-source models, at least on the human evaluations we performed (see\n",
            "Figures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\n",
            "Document ID llama2_removed_16: annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\n",
            "thispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\n",
            "LLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\n",
            "continue to improve the safety of those models, paving the way for more responsible development of LLMs.\n",
            "Wealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\n",
            "Document ID llama2_removed_17: the emergence of tool usage and temporal organization of knowledge.\n",
            "3 Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\n",
            "source models. Human raters judged model generations for safety violations across ~2,000 adversarial\n",
            "prompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\n",
            "importanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\n",
            "Document ID llama2_removed_18: promptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\n",
            "safety evaluations are performed using content standards that are likely to be biased towards the Llama\n",
            "2-Chatmodels.\n",
            "We are releasing the following models to the general public for research and commercial use‡:\n",
            "1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\n",
            "increasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\n",
            "Document ID llama2_removed_19: adoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\n",
            "7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\n",
            "but are not releasing.§\n",
            "2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\n",
            "variants of this model with 7B, 13B, and 70B parameters as well.\n",
            "WebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\n",
            "Document ID llama2_removed_2: Sergey Edunov Thomas Scialom∗\n",
            "GenAI, Meta\n",
            "Abstract\n",
            "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
            "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
            "Our fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\n",
            "models outperform open-source chat models on most benchmarks we tested, and based on\n",
            "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\n",
            "Document ID llama2_removed_20: Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\n",
            "Solaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\n",
            "all scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\n",
            "safetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\n",
            "Document ID llama2_removed_21: guide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\n",
            "our responsible release strategy can be found in Section 5.3.\n",
            "Theremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\n",
            "(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\n",
            "work (Section 6), and conclusions (Section 7).\n",
            "‡https://ai.meta.com/resources/models-and-libraries/llama/\n",
            "Document ID llama2_removed_22: §We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\n",
            "¶https://ai.meta.com/llama\n",
            "‖https://github.com/facebookresearch/llama\n",
            "4 Figure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\n",
            "availableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\n",
            "ofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\n",
            "Document ID llama2_removed_23: with Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\n",
            "Optimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\n",
            "parallel with model enhancements is crucial to ensure the reward models remain within distribution.\n",
            "2 Pretraining\n",
            "Tocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\n",
            "Document ID llama2_removed_24: (2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\n",
            "Specifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\n",
            "tokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\n",
            "for our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\n",
            "2.1 Pretraining Data\n",
            "Document ID llama2_removed_25: 2.1 Pretraining Data\n",
            "Our training corpus includes a new mix of data from publicly available sources, which does not include data\n",
            "fromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\n",
            "highvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\n",
            "providesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\n",
            "knowledge and dampen hallucinations.\n",
            "Document ID llama2_removed_26: knowledge and dampen hallucinations.\n",
            "Weperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\n",
            "capabilities and limitations of our models; results can be found in Section 4.1.\n",
            "2.2 Training Details\n",
            "We adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\n",
            "transformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\n",
            "Document ID llama2_removed_27: Sennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\n",
            "(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\n",
            "andgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\n",
            "ablation experiments to demonstrate their importance.\n",
            "Hyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\n",
            "Document ID llama2_removed_28: 0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\n",
            "finallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\n",
            "of1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\n",
            "5 Training Data Params Context\n",
            "LengthGQA Tokens LR\n",
            "Llama 1See Touvron et al.\n",
            "(2023)7B 2k ✗ 1.0T 3.0×10−4\n",
            "13B 2k ✗ 1.0T 3.0×10−4\n",
            "33B 2k ✗ 1.4T 1.5×10−4\n",
            "65B 2k ✗ 1.4T 1.5×10−4\n",
            "Llama 2A new mix of publicly\n",
            "Document ID llama2_removed_29: Llama 2A new mix of publicly\n",
            "available online data7B 4k ✗ 2.0T 3.0×10−4\n",
            "13B 4k ✗ 2.0T 3.0×10−4\n",
            "34B 4k ✓ 2.0T 1.5×10−4\n",
            "70B 4k ✓ 2.0T 1.5×10−4\n",
            "Table 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\n",
            "a global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\n",
            "improved inference scalability.\n",
            "0 250 500 750 1000 1250 1500 1750 2000\n",
            "Processed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\n",
            "7B\n",
            "13B\n",
            "Document ID llama2_removed_3: source models. We provide a detailed description of our approach to fine-tuning and safety\n",
            "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
            "contribute to the responsible development of LLMs.\n",
            "∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
            "†Second author\n",
            "Contributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023 Contents\n",
            "1 Introduction 3\n",
            "2 Pretraining 5\n",
            "Document ID llama2_removed_30: 7B\n",
            "13B\n",
            "34B\n",
            "70B\n",
            "Figure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\n",
            "We observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\n",
            "Tokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\n",
            "etal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\n",
            "Document ID llama2_removed_31: we split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\n",
            "vocabulary size is 32k tokens.\n",
            "2.2.1 Training Hardware & Carbon Footprint\n",
            "TrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\n",
            "2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\n",
            "between the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\n",
            "Document ID llama2_removed_32: InfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\n",
            "based on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\n",
            "seconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\n",
            "uses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\n",
            "interconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\n",
            "6 Time\n",
            "(GPU hours)Power\n",
            "Document ID llama2_removed_33: 6 Time\n",
            "(GPU hours)Power\n",
            "Consumption (W)Carbon Emitted\n",
            "(tCO 2eq)\n",
            "Llama 27B 184320 400 31.22\n",
            "13B 368640 400 62.44\n",
            "34B 1038336 350 153.90\n",
            "70B 1720320 400 291.42\n",
            "Total 3311616 539.00\n",
            "Table 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\n",
            "Consumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\n",
            "100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\n",
            "Document ID llama2_removed_34: these models, the pretraining costs do not need to be incurred by others.\n",
            "can scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\n",
            "democratizable.\n",
            "Carbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\n",
            "Wu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\n",
            "Document ID llama2_removed_35: efficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\n",
            "actualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\n",
            "Power(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\n",
            "do not account for further power demands, such as those from interconnect or non-GPU server power\n",
            "consumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\n",
            "Document ID llama2_removed_36: of AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\n",
            "Table 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\n",
            "3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\n",
            "We estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\n",
            "Document ID llama2_removed_37: sustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\n",
            "be incurred by other companies, saving more global resources.\n",
            "2.3 Llama 2 Pretrained Model Evaluation\n",
            "In this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\n",
            "Transformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\n",
            "Document ID llama2_removed_38: For all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\n",
            "modelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\n",
            "any publicly reported results.\n",
            "InTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\n",
            "benchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\n",
            "results for all the individual benchmarks are available in Section A.2.2.\n",
            "Document ID llama2_removed_39: •Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\n",
            "MBPP (Austin et al., 2021).\n",
            "•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\n",
            "HellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\n",
            "(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\n",
            "2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\n",
            "Document ID llama2_removed_4: 1 Introduction 3\n",
            "2 Pretraining 5\n",
            "2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
            "2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
            "2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n",
            "3 Fine-tuning 8\n",
            "3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
            "Document ID llama2_removed_40: •WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\n",
            "2019) and TriviaQA (Joshi et al., 2017) and report the average.\n",
            "•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\n",
            "(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\n",
            "•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\n",
            "(Hendrycks et al., 2021) benchmarks at top 1.\n",
            "Document ID llama2_removed_41: (Hendrycks et al., 2021) benchmarks at top 1.\n",
            "∗∗https://sustainability.fb.com/2021-sustainability-report/\n",
            "††https://www.mosaicml.com/blog/mpt-7b\n",
            "7 Model Size CodeCommonsense\n",
            "ReasoningWorld\n",
            "KnowledgeReading\n",
            "ComprehensionMath MMLU BBH AGI Eval\n",
            "MPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\n",
            "30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\n",
            "Falcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\n",
            "40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\n",
            "Llama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\n",
            "Document ID llama2_removed_42: Llama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\n",
            "13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\n",
            "33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\n",
            "65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\n",
            "Llama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\n",
            "13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\n",
            "34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\n",
            "70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\n",
            "Table3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\n",
            "Document ID llama2_removed_43: •Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\n",
            "et al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\n",
            "et al., 2023). For AGI Eval, we only evaluate on the English tasks and report the average.\n",
            "As shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\n",
            "resultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\n",
            "Document ID llama2_removed_44: modelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\n",
            "Falcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\n",
            "Additionally, Llama 2 70B model outperforms all open-source models.\n",
            "In addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\n",
            "in Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\n",
            "Document ID llama2_removed_45: gaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\n",
            "2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\n",
            "and PaLM-2-L.\n",
            "We also analysed the potential data contamination and share the details in Section A.6.\n",
            "Benchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\n",
            "MMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\n",
            "TriviaQA (1-shot) – – 81.4 86.1 85.0\n",
            "Natural Questions (1-shot) – – 29.3 37.5 33.0\n",
            "GSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\n",
            "Document ID llama2_removed_46: GSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\n",
            "HumanEval (0-shot) 48.1 67.0 26.2 – 29.9\n",
            "BIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\n",
            "Table 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\n",
            "are from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\n",
            "PaLM-2-L are from Anil et al. (2023).\n",
            "3 Fine-tuning\n",
            "Llama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\n",
            "Document ID llama2_removed_47: including both instruction tuning and RLHF, requiring significant computational and annotation resources.\n",
            "In this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\n",
            "well as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\n",
            "new technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\n",
            "(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\n",
            "8\n",
            "Document ID llama2_removed_5: 3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\n",
            "3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n",
            "3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
            "4 Safety 20\n",
            "4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n",
            "Document ID llama2_removed_6: 4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n",
            "4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n",
            "4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n",
            "5 Discussion 32\n",
            "5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n",
            "Document ID llama2_removed_7: 5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n",
            "5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n",
            "6 Related Work 35\n",
            "7 Conclusion 36\n",
            "A Appendix 46\n",
            "A.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n",
            "A.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n",
            "Document ID llama2_removed_8: A.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n",
            "A.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n",
            "A.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n",
            "A.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n",
            "Document ID llama2_removed_9: A.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n",
            "2 Figure 1: Helpfulness human evaluation results for Llama\n",
            "2-Chatcomparedtootheropen-sourceandclosed-source\n",
            "models. Human raters compared model generations on ~4k\n",
            "promptsconsistingofbothsingleandmulti-turnprompts.\n",
            "The95%confidenceintervalsforthisevaluationarebetween\n",
            "1%and2%. MoredetailsinSection3.4.2. Whilereviewing\n",
            "these results, it is important to note that human evaluations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0HoxLdvsrGW",
        "outputId": "cba84cdf-6228-4055-cc7e-93bdef843a83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['105InvestmentPolicyStatement_0',\n",
              "  '105InvestmentPolicyStatement_1',\n",
              "  '105InvestmentPolicyStatement_10',\n",
              "  '105InvestmentPolicyStatement_11',\n",
              "  '105InvestmentPolicyStatement_12',\n",
              "  '105InvestmentPolicyStatement_13',\n",
              "  '105InvestmentPolicyStatement_14',\n",
              "  '105InvestmentPolicyStatement_15',\n",
              "  '105InvestmentPolicyStatement_16',\n",
              "  '105InvestmentPolicyStatement_17',\n",
              "  '105InvestmentPolicyStatement_18',\n",
              "  '105InvestmentPolicyStatement_19',\n",
              "  '105InvestmentPolicyStatement_2',\n",
              "  '105InvestmentPolicyStatement_20',\n",
              "  '105InvestmentPolicyStatement_21',\n",
              "  '105InvestmentPolicyStatement_22',\n",
              "  '105InvestmentPolicyStatement_23',\n",
              "  '105InvestmentPolicyStatement_24',\n",
              "  '105InvestmentPolicyStatement_25',\n",
              "  '105InvestmentPolicyStatement_26',\n",
              "  '105InvestmentPolicyStatement_27',\n",
              "  '105InvestmentPolicyStatement_28',\n",
              "  '105InvestmentPolicyStatement_29',\n",
              "  '105InvestmentPolicyStatement_3',\n",
              "  '105InvestmentPolicyStatement_30',\n",
              "  '105InvestmentPolicyStatement_31',\n",
              "  '105InvestmentPolicyStatement_32',\n",
              "  '105InvestmentPolicyStatement_33',\n",
              "  '105InvestmentPolicyStatement_34',\n",
              "  '105InvestmentPolicyStatement_35',\n",
              "  '105InvestmentPolicyStatement_36',\n",
              "  '105InvestmentPolicyStatement_37',\n",
              "  '105InvestmentPolicyStatement_38',\n",
              "  '105InvestmentPolicyStatement_39',\n",
              "  '105InvestmentPolicyStatement_4',\n",
              "  '105InvestmentPolicyStatement_40',\n",
              "  '105InvestmentPolicyStatement_41',\n",
              "  '105InvestmentPolicyStatement_42',\n",
              "  '105InvestmentPolicyStatement_43',\n",
              "  '105InvestmentPolicyStatement_44',\n",
              "  '105InvestmentPolicyStatement_45',\n",
              "  '105InvestmentPolicyStatement_46',\n",
              "  '105InvestmentPolicyStatement_47',\n",
              "  '105InvestmentPolicyStatement_48',\n",
              "  '105InvestmentPolicyStatement_49',\n",
              "  '105InvestmentPolicyStatement_5',\n",
              "  '105InvestmentPolicyStatement_50',\n",
              "  '105InvestmentPolicyStatement_6',\n",
              "  '105InvestmentPolicyStatement_7',\n",
              "  '105InvestmentPolicyStatement_8',\n",
              "  '105InvestmentPolicyStatement_9',\n",
              "  'llama2_removed_0',\n",
              "  'llama2_removed_1',\n",
              "  'llama2_removed_10',\n",
              "  'llama2_removed_11',\n",
              "  'llama2_removed_12',\n",
              "  'llama2_removed_13',\n",
              "  'llama2_removed_14',\n",
              "  'llama2_removed_15',\n",
              "  'llama2_removed_16',\n",
              "  'llama2_removed_17',\n",
              "  'llama2_removed_18',\n",
              "  'llama2_removed_19',\n",
              "  'llama2_removed_2',\n",
              "  'llama2_removed_20',\n",
              "  'llama2_removed_21',\n",
              "  'llama2_removed_22',\n",
              "  'llama2_removed_23',\n",
              "  'llama2_removed_24',\n",
              "  'llama2_removed_25',\n",
              "  'llama2_removed_26',\n",
              "  'llama2_removed_27',\n",
              "  'llama2_removed_28',\n",
              "  'llama2_removed_29',\n",
              "  'llama2_removed_3',\n",
              "  'llama2_removed_30',\n",
              "  'llama2_removed_31',\n",
              "  'llama2_removed_32',\n",
              "  'llama2_removed_33',\n",
              "  'llama2_removed_34',\n",
              "  'llama2_removed_35',\n",
              "  'llama2_removed_36',\n",
              "  'llama2_removed_37',\n",
              "  'llama2_removed_38',\n",
              "  'llama2_removed_39',\n",
              "  'llama2_removed_4',\n",
              "  'llama2_removed_40',\n",
              "  'llama2_removed_41',\n",
              "  'llama2_removed_42',\n",
              "  'llama2_removed_43',\n",
              "  'llama2_removed_44',\n",
              "  'llama2_removed_45',\n",
              "  'llama2_removed_46',\n",
              "  'llama2_removed_47',\n",
              "  'llama2_removed_5',\n",
              "  'llama2_removed_6',\n",
              "  'llama2_removed_7',\n",
              "  'llama2_removed_8',\n",
              "  'llama2_removed_9'],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None],\n",
              " 'documents': [\"Section 1.05  \\nPage 1 of 9 \\n \\nMURRAY STATE UNIVERSITY FOUNDATION, INC.  \\nPOLICY  \\n \\n \\nSUBJECT:  Investment Policy Statement  \\n \\nDATE :  November 15, 2015  \\n \\nI. Purpose  \\n \\nInvestments made  by the Murray  State  University  Foundation,  Inc. (“Foundation ”) are \\nto be managed  in such a way that maximizes the  Foundation's  ability  to contribute  to \\nthe goals  of Murray  State  University  (“University ”).  The investment  policy statement\",\n",
              "  '(“Policies”)  for the investment  of monies  and securities ( “Portfolio ”) owned  or under  \\nthe custodial  care of the Foundation  is established  by a Joint  Investments  Committee \\n(“Joint Investment s Committee ”) with limited  authority being granted  to a sub -\\ncommittee, Investment Committee, as defined in Section Three.   \\n \\nThe purpose of this investment policy statement is to establish guidelines for the',\n",
              "  'investment po licies, and will be limited to P ortfolio changes of  10% or less of the \\nPortfolio (or  sometimes referred to as Investment P ool), cumulatively, between \\nregularly scheduled board meetings (i.e. if the investment pool is $90 million, then \\ncumulative changes between board meetings shall be limited to $9 million).  If \\nextraordinary circumstance s exist, and it is deemed by the Investment Committee',\n",
              "  'that Portfolio changes greater than 10% (cumulatively) should occur, then the Joint \\nInvestments Committee  shall be consulted by a conference call as soon as \\nreasonably possible.  \\n \\nC. Portfolio  changes  made  between  board  meetings  by the Investment Committee  will \\nbe presented  to the Joint  Investments  Committee  and Board  of Trustees  at the \\nnext scheduled  board  meeting  for ratification of  all actions pursuant  to this policy.',\n",
              "  'D. In addition,  the Investment  Committee  does not have  the authority  to hire new \\ninvestment  managers  between  board  meetings, change  existing  investment \\nmanagers, or  change  overall  investment  policy,  but will have the ability  to make \\nrecommendations  regarding  new or existing  investment  managers  to the Joint \\nInvestments  Committee  at  the  next  board  meeting.     Changes  in  existing \\ninvestment  managers,  the hiring  of new investment  managers, or  changes  in',\n",
              "  'investment  policy,  shall  be  conducted  by  the  Joint  Investments  Committee \\nthrough  an agreed process  and approved  by the Board  of Trustees. Section 1.05  \\nPage 3 of 9 \\n \\nE. The Investment  Committee  shall  in writing  direct  the President  of the Foundation \\nto make  approved  changes  in the Portfolio  within  the parameters of these  \\nguidelines.  \\n \\nIV. Investment Objective and Spending  Policy',\n",
              "  'IV. Investment Objective and Spending  Policy  \\n \\nA. The F oundation  is to invest  with the objective of preserving the long -term, real \\npurchasing power of assets while providing a relatively predictable and growing \\nstream of annual di stributions  (“Spending Rate”)  in support of the University .  \\n \\nB. For the purpose of making distributions, the F oundation shall make use of a total \\nreturn based spending policy, meaning that it will fund distributions from net',\n",
              "  'investment income, net realized c apital gains, and proceeds from the sale of \\ninvestments.  \\n \\nC. The distribution of F oundation  assets will be permitted to the extent that such \\ndistributions do not exceed a level that would erode the F oundation ’s real assets \\nover time. The Joint Investments Committee will seek to reduce the variability of \\nannual F oundation  distributions by factori ng past spending and Portfolio asset',\n",
              "  'values into its current spending decisions.  The Joint Investments Committee  will \\nreview spending assumptions annually upon a recommendation by the Foundation \\nPresident for the purpose of deciding  the annual Spending Rate,  whether any \\nchanges therein necessitate amending the F oundation ’s spending policy, its target \\nasset allocation, or both.  In addition, the Board of Trustees shall approve the annual \\nSpending Rate upon a recommendation by the Foundation Presi dent and approval',\n",
              "  'by the Joint Investments Committee.  \\n \\nD. Periodic cash flow, either into or out of the Portfolio, will be used to better align \\nthe P ortfolio to the target asset allocation outlined in the Asse t Allocation Policy at \\nSection V. A. herein.   \\n \\nV. Portfolio Investment Policies  \\n \\nA. Asset Allocation Policy  \\n \\n1. The Joint Investments Committee  recognizes that the strategic allocation of \\nPortfolio assets across broadly -defined financial asset and sub -asset categories',\n",
              "  'with varying degrees of risk, return, and return correlation will be the most \\nsignificant determinant of long -term investment returns and Portfolio asset \\nvalue stability.   \\n \\n2. The Joint Investments Committee  expects that actual returns and return \\nvolatility may vary widely from expectations and retu rn objectives across short \\nperiods of time.  While the Joint Investments Committee  wishes to retain \\nflexibility with respect to making periodic changes to the Portfolio’s asset',\n",
              "  'allocation, it expects to do so only in the event of material changes to the \\nFoundation , to the assumptions underlying F oundation  spending policies, \\nand/or to the capital markets and asset classes in which the Portfolio invests. Section 1.05  \\nPage 4 of 9 \\n \\n3. Foundation  assets will be managed as a balanced portfolio comprised of two \\nmajor components: an equity portion and a fixed income portion.  The expected',\n",
              "  'Foundation ’s investment Portfolio  in the areas that most influence investment returns \\nand risks.  The investment policy statement also incorporates accountability standards \\nthat will be used for monitoring the progress of the Portfolio’s investment program and \\nfor evaluating t he contributions of the managers  hired on behalf of the F oundation  and \\nits beneficiaries.  \\n \\nII. Role of the Joint Investment s Committee',\n",
              "  'role of F oundation  equity investments will be to maximize the long -term real \\ngrowth of Portfolio assets, while the role of fixed income investments will be \\nto generate current income, provide for more stabl e periodic returns, and \\nprovide some protection against a prolonged decline in the market value of \\nPortfolio equity investments.  The Board of Trustees  will determine  the \\nappropriate  mix between  equities  and fixed  income. The Board of  Trustees',\n",
              "  'may choose  to invest  up to 70%,  or more,  of available  funds  in equities . \\nHowever,  the Board of Trustees  may also reduce  equity  exposure  to as low as  \\n40%,  or less, when  they deem  it appropriate.  The remainder  will be invested  in \\nfixed  income  securities,  including  cash reserves,  which  the Board of Trustees  \\nmay retain,  separate  from  the managers  from time  to time.  \\n \\n4. Cash investments will, under normal circumstances, only be considered as',\n",
              "  'temporary Portfolio holdings, and will be used for the Foundation ’s liquidity \\nneeds or to facilitate a planned program of dollar cost averaging into \\ninvestments in either or both of t he equity and fixed income asset classes.  \\n \\n5. Outlined below are the long -term strategic asset allocation guidelines, \\ndetermined by the Joint Investments Committee  to be the most appropriate, \\ngiven the F oundation ’s long -term objectives and short -term constrai nts.',\n",
              "  'Portfolio assets will, under normal circumstances, be allocated across broad \\nasset and sub -asset classes in accordance with the following guidelines:  \\n \\nAsset Class  Sub-Asset Class  Target Allocation  \\nEquity    65% \\n Domestic (U.S.)  39% \\n International (Non -U.S.)  26% \\n   \\nFixed Income   34% \\n Investment Grade  34% \\n   \\nReal Estate  Real Estate Investment \\nTrusts  1% \\n   \\nCash   0% \\n \\nB. Diversification Policy',\n",
              "  'Cash   0% \\n \\nB. Diversification Policy  \\n \\nDiversification across and within asset classes is the primary means by which the \\nJoint Investments Committee  expects the Portfolio to avoid undue risk of large \\nlosses over long time periods.  To protect the Portfolio against unfavorable \\noutcomes within an  asset class due to the assumption of large risks, the Joint \\nInvestments Committee  will take reasonable precautions to avoid excessive',\n",
              "  'investment concentrations.  Specifically, the following guidelines will be in place: Section 1.05  \\nPage 5 of 9 \\n \\n1. With the exception of fixed income investments explicitly guaranteed by the \\nU.S. government, no single investment security shall represent more than 5% \\nof total Portfolio assets.  \\n \\n2. With the exception of passively managed investment vehicles seeking to match \\nthe returns on a broadly diversifi ed market index, no single investment pool or',\n",
              "  'investment company (mutual fund) shall comprise more than 20% of total \\nPortfolio assets.  \\n \\nC. Rebalancing Policies  \\n \\nIt is expected that the Portfolio’s actual asset allocation will vary from its target \\nasset allocation as a result of the varying periodic returns earned on its \\ninvestments in different asset and sub -asset classes.  The Portfolio will be re -\\nbalanced to its  target normal asset allocation as follows :',\n",
              "  '1. Utilize incoming cash flow (contributions) or outgoing money mo vements \\n(disbursements) of the P ortfolio to realign the current weightings closer to  the \\ntarget weightings for the P ortfolio.  \\n \\n2. The P ortfolio will be  reviewed quarterly  with the I nvestment Committee and \\nPresident of the Foundation  to determine the deviation from target weightings. \\nDuring each quarterly review, the following parameters will be applied:',\n",
              "  'a) If any asset class (equi ty or fixed income) withi n the P ortfolio is  +/ -5 \\npercentage points from its target weighting,  the P ortfolio will be rebalanced.  \\n \\nb) If any fund within the P ortfolio has increased or decreased by greater than \\n20% of its target weighting, the fund may be rebalanced.  \\n \\n3. The President of the Foundation or Controller  will provide the  investment \\nmanager s with quart erly fixed income statements in order to determine  possible \\nPortfolio rebalancing.',\n",
              "  'Portfolio rebalancing.  \\n  \\n4. The investment manager s may provide  rebalancing recommendation s at any \\ntime.  \\n \\n5. The investment manager s shall act within a reasonable period of time to \\nevaluate deviation from these ranges.  \\n \\nD. Policies Governing Investment Discretion and Authorized/Prohibited \\nTransactions  \\n \\n1. The Joint Investments Committee authorizes the outside investment manager, \\nto invest in equity securities as of October 13, 1995.',\n",
              "  'II. Role of the Joint Investment s Committee  \\n \\nThe Joint Investment s Committee is comprised of  at least  three trustees of the \\nFoundation, two members of the Board of Regents, and two members of the Murray \\nState University Alumni Board of  Governors . The Joint Investments Committee is \\nacting in a fiduciary capacity with respect to the Portfolio, and is accountable to the \\nBoard  of Trustees  for overseeing the investment of all assets included in the Portfolio.',\n",
              "  '2. The Joint  Investments  Committee authorizes  the outside  investment  manager s \\nto also invest  in fixed  income  accounts  as of June 10, 1998.  The policy Section 1.05  \\nPage 6 of 9 \\n \\nis included  below in “Investment Guidelines for Fixed Income \\nManagers.”  \\n   \\n3. The Joint  Investments  Committee  authorizes  the Investment  Committee  to \\nmake investments  of  excess  cash  not  being  invested  through  the  \\ninvestment  manager s  as follows:',\n",
              "  'investment  manager s  as follows:  \\n \\na. Cash  funds  available  for investments  shall,  whenever  possible,  be \\npooled  into amounts of $100,000 or more.  \\n \\nb. Cash  funds shall  be invested  for short -term periods  in non -speculative , \\nliquid assets such as Treasury Securities, Certificates of Deposit , Money \\nMarket Funds, or other Government backed securities .  It may be \\nnecessary to use collateralization vehicles such as a letter of credit to',\n",
              "  'fully secure short -term, liquid investments.  \\n \\nc. A maximum  investment  of $250 ,000  shall  be held in any institution  at \\na given  time.    (Exception:   A local ly negotiated , fully secured \\narrangement  for the  investment  of checking  account  funds,  as permitted  \\nby cash flow requirements.)  \\n \\nd. No investment  shall  be placed  with any institution  on the basis  of \\npolitical  favor, friendship,  or influence  by any officials,  alumnus  or',\n",
              "  'friend  of the University. Competitive, safe,  and best bids shall be \\nsought  for all funds  invested  by Foundation  officials.  \\n \\ne. Funds  in checking  accounts  will be invested  in negotiated  short -term \\ncertificates  of deposit,  prime  accounts,  money  market  accounts  or other  \\ninsured, interest  bearing  accounts.  \\n \\n4. The purchase  of real estate  shall be authorized by  the Investment Committee \\nor Joint Investment  Committee.',\n",
              "  \"or Joint Investment  Committee.  \\n \\n5. Pooled  investment  earnings,  including  realized  and unrealized  gains  and \\nlosses, shall  be pro-rated  to the individual  investment  accounts  in accordance  \\nwith the amount  of funds  invested.  This allocation  will be  made  based  on the \\nmarket  value of  each fund's  principal  balance  at the beginning  of the quarter.  \\n \\nE. Investment  Guidelines  for Fixed  Income  Managers\",\n",
              "  \"1. Investments will be mostly limited to marketable debt securities rated at the \\ntime of purchase within the four highest investment grade ratings (BBB, Baa or \\nbetter) assigned by Moody's Investors Service, Inc. or Standard & Poor's \\nCorporation or which, alth ough not rated by either agency, are deemed as being \\nof investment quality equivalent.  \\n \\n2. Fixed  income  securities  return  expectations  are to exceed  the Bloomberg US\",\n",
              "  'Aggregate Bond Index  or other  similar  index,  as deemed  acceptable  to the \\nJoint Investments Committee  over one, three  and five years.  The Portfolio’s Section 1.05  \\nPage 7 of 9 \\n \\nduration should be within a range of +/ - 20% of the duration of the  \\nIndex  \\n \\n3. Not more  than twenty  percent  (20%)  of the fixed  income portion of the \\nPortfolio  may be invested  in any one  broadly  defined  industry,  regardless  of',\n",
              "  'the number  of individual  holdings. Not  more  than five percent  (5%)  of the \\nfixed  income  portfolio  may be  invested  in any one corporate  issuer,  at cost,  \\nspecifically  excluding  U.S. Treasury,  GNMA, FNMA,  FHLB  and any other  \\ngovernment  sponsored  enterprise  securities.  (U.S. Treasury  and GNMA  also \\nexcluded  from  the 20% limit  above).  \\n \\n4. Up to 5.0% of  the assets in  the fixed income portion of the Portfolio may be',\n",
              "  'securities of  investment grade  foreign issuers, including emerging markets \\nsecurities.    \\n \\n5. The fixed income portion of the Portfolio may include corporate securities, U.S. \\nGovernment securities, zero coupon securities, mortgage -backed securities, \\ncommercial mortgage backed securities (CMBS), collateralized mortgage \\nobligations,  asset backed securities, equipment trust certificates, taxable \\nmunicipal bonds, preferred securities, and real estate investment trusts ( REITs ).',\n",
              "  \"No more than twenty percent (20%) of the fixed income portion of the Portfolio \\nmay be invested in a combination of the following asset types: asset backed \\nsecurities, equipment trust certificates, taxable municipal bonds, preferred \\nsecurities, and real estate investment trusts.  \\n \\n6. In order  to ensure  overall  diversification  (maturity,  sector,  issuer,  quality,  etc.),  \\nall the Foundation's  fixed  income  holdings  will be taken  into consideration\",\n",
              "  'A. The Policies set forth the inve stment objectives, distribution policies, and \\ninvestment guidelines that govern the activities of the Joint Investments Committee  \\nand any other parties to whom the Joint Investments Committee  has delegated \\ninvestment management responsibility for Portfolio  assets.  \\n \\nB. Quarterly investment management statements of the Foundation’s P ortfolio as \\nprepared by our investment managers are sent to the Joint Investments Committee .',\n",
              "  'when making  investment  decisions.  \\n \\n7. Mutual funds and other types of commingled investment vehicles provide, \\nunder some circumstances, lower costs and better diversification than can be \\nobtained with separately managed portfolios pursuing the same investment \\nobjectives. However, commingled in vestment funds cannot customize their \\ninvestment policies and guidelines to the specific needs of individual clients.',\n",
              "  'Therefore, if the Foundation selects a mutual fund or other type of commingled \\nvehicle for investment, either directly or through an inve stment management \\nagreement, then the written guidelines and policies of the commingled fund or \\nthe prospectus and statement of additional information for the mutual fund, and \\nany provisions set forth in any investment management agreement will replace \\nthis Policy Statement for these particular type of investments. The Manager or',\n",
              "  'other fund representative will provide a copy of the applicable commingled or \\nmutual fund guidelines, policies, prospectus and other governing documents to \\nthe Foundation.  \\n \\nF. Other I nvestment Policies  \\n \\nUnless expressly authorized by the Joint Investments Committee , the Portfolio , \\nthe underlying funds,  and its investment managers are prohibited from: Section 1.05  \\nPage 8 of 9 \\n \\n1. Purchasing securities on margin, or executing short sales.',\n",
              "  '2. Pledging or hypothecating  securiti es, except for loans of securities that are fully \\ncollateralized within the mutual fund investment.  \\n \\n3. Purchasing or selling derivative securities for speculation or leverage.  \\n \\n4. Purchasing corporate bonds that are convertible to equity.  \\n \\n5. Purchasing highly levered mortgage securities, which for the purpose of this \\npolicy, are defined as inverse floating rate securities, interest or principal only \\nstrips, or any combination thereof.',\n",
              "  'strips, or any combination thereof.  \\n \\n6. Purchases of real estate, oil & gas properties, or other n atural resource related \\nproperties with the exception of REITs or marketable real estate securities.  \\n \\n7. Investments in limited partnerships.  \\n \\n8. Purchasing Repurchase Agreements, Senior Loans, Collater alized Debt \\nObligations, Collateralized Bond Obligations, Co llateralized Loan Obligations, \\nStructured Investment Vehicles, Special Purpose Entity Obligations, swaps or',\n",
              "  'other derivative contracts.  \\n \\n9. Engaging in investment strategies that have the potential to amplify or distort \\nthe risk of loss beyond a level that is  reasonably expected given the objectives \\nof their portfolios . \\n \\nVI. Monitoring Portfolio Investments and Performance  \\n \\nThe Investment Committee and Joint Investments Committee  will monitor the \\nPortfolio’s investment performance against the Portfolio’s stated investment',\n",
              "  'objectives. T he Investment Committee and Joint Investments Committee  will formally \\nassess the Portfolio and the performance of its underlying investments as follows:  \\n \\nA. The Portfolio’s composite investment performance (net of fees) will be  judged \\nagainst the following standards:  \\n \\n1. The Portfolio’s absolute long -term real return objective . \\n \\n2. A composite benchmark consisting of the following unmanaged market indices',\n",
              "  'weighted according to the expected target asset allocations stipulated by the \\nPortfolio’s investment guidelines . \\n \\na) U.S. Equity:  CRSP US Total Market Index  or a similar broad domestic \\nequity index . \\n \\nb) Non-U.S. Equity:  FTSE Global All Cap ex US Index or a similar broad \\ninternational equity index . Section 1.05  \\nPage 9 of 9 \\n \\nc) Investment Grade Fixed Income:  Bloomberg US Aggregate Bond Index.  \\n \\nd) Real Estate Investment Trusts: MSCI US REIT Index .',\n",
              "  'e) Cash: Citigroup 3 -Month T -Bill Index . \\n \\nB. The performance of professional investment managers hired on behalf of the \\nPortfolio will be judg ed against the following standards:  \\n \\n1. A market -based index appropriately selec ted or tailored to the managers’  \\nagreed -upon investment objective and the normal investment characteristics of \\nthe managers’  portfolio . \\n \\n2. The performance of other investment manage rs having similar investment \\nobjectives .',\n",
              "  'objectives . \\n \\nC. In keeping with the Portfolio’s overall long -term financial objective, the Investment \\nCommittee and Joint Investments Committee  will evaluate Portfolio and manager \\nperformance over a suitably long -term investment horizon, generally across full \\nmarket cycles or, at a minimum, on a rolling five -year basis.  \\n \\nD. Investment reports shall be provi ded by the investment managers  on a (fiscal) \\nquarterly    basis or as more frequently requested by the Joint Investmen ts',\n",
              "  'C. The Joint Investments Committee  meets twice a year at  the regular Board meetings \\nof the Foundation, and at such other times as deemed necessary.  The quarterly \\nInvestment R eport of invested funds is prepared by the Foundation staff and \\ndistributed to members of the Joint Investments Committee, the T reasurer,  and to \\nthe full Board of Trustees , including ex -officio members,  on a quarterly basis .',\n",
              "  'Committee.   Each investment manager is expected to be available to meet with the \\nJoint Investments Committee and Board of Trustees at least twice per year to review \\nPortfolio structure, strategy, and investment performance.  Additionally, the \\ninvestmen t manager s will be available to the Investment Committee for quarterly \\nconference calls and as needed by the President of the Foundation.       \\n \\n \\n \\nRevised:  April 23, 2022',\n",
              "  'D. The Policies for the F oundation  contained herein have been  formulated consistent \\nwith anticipated financial needs and in consideration of t he tolerance for assuming Section 1.05  \\nPage 2 of 9 \\n \\ninvestment and financial risk, as reflected in the majority opinion of the Joint \\nInvestments Committee .     \\n \\nE. The Policies contained in this statement are intended to provide boundaries, where \\nnecessary, for ensuring that the Portfolio’s investments are man aged consistent',\n",
              "  'with the short -term and long -term financial goals of the Foundation .  At the same \\ntime, they are intended to provide for sufficient investment flexibility in the face of \\nchanges in capital market conditions and in the financial circumstance s of the  \\nFoundation and  University . \\n \\nF. The Policies will be reviewed by the Joint Investments Committee and the Board \\nof Trustees of the Foundation on an annual basis or more often as needed. Changes',\n",
              "  \"may be made at their discretion and in consultation with t he investment manager s. \\n \\nIII. Investment Committee Authority and Guidelines  \\n \\nA. The Investment Committee as provided for in Article 3, Section 3 of the Foundation  \\nBy-Laws, and as approved at the October 9,  2009  Board of Trustees meeting allows \\nfor a three member Investment Committee  (“Investment Committee”)  to make \\nchanges to the Foundation's Portfolio between regularly scheduled board meetings.\",\n",
              "  \"This policy ratifies the intent of the Foundation's By -Laws and pre vious actions by \\nthe Board of Trustees to grant limited authority to the Investment Committee to \\nmake specific changes to the P ortfolio between regularly scheduled board meetings \\nin order to be efficient in our investment mana gement process and to maximize  \\nPortfolio performance.  \\n \\nB. The Investment Committee will be required to adhere to the Foundation's existing\",\n",
              "  'Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev',\n",
              "  'Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic',\n",
              "  'canbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in',\n",
              "  'ties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive',\n",
              "  'chat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave',\n",
              "  'limited the development of LLMs to a few players. There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such',\n",
              "  'asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and',\n",
              "  'Llama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata',\n",
              "  'annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas',\n",
              "  'the emergence of tool usage and temporal organization of knowledge.\\n3 Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe',\n",
              "  'promptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and',\n",
              "  'adoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,',\n",
              "  'Sergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-',\n",
              "  'Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse',\n",
              "  'guide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/',\n",
              "  '§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4 Figure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning',\n",
              "  'with Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.',\n",
              "  '(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data',\n",
              "  '2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.',\n",
              "  'knowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and',\n",
              "  'Sennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=',\n",
              "  '0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5 Training Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly',\n",
              "  'Llama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.\\n0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B',\n",
              "  'source models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023 Contents\\n1 Introduction 3\\n2 Pretraining 5',\n",
              "  '7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,',\n",
              "  'we split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum',\n",
              "  'InfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6 Time\\n(GPU hours)Power',\n",
              "  '6 Time\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing',\n",
              "  'these models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon',\n",
              "  'efficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction',\n",
              "  'of AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s',\n",
              "  'sustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.\\n2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.',\n",
              "  'For all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.',\n",
              "  '•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.',\n",
              "  '1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9',\n",
              "  '•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.',\n",
              "  '(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7 Model Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9',\n",
              "  'Llama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.',\n",
              "  '•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023). For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B',\n",
              "  'modelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant',\n",
              "  'gaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8',\n",
              "  'GSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,',\n",
              "  'including both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8',\n",
              "  '3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20',\n",
              "  '4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32',\n",
              "  '5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47',\n",
              "  'A.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75',\n",
              "  'A.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2 Figure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations'],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents']}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_60dynvLsq0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to update a specific PDF document in the collection\n",
        "# def update_pdf_in_collection(pdf_path, doc_id_prefix):\n",
        "#     # Delete existing chunks for the document\n",
        "#     existing_doc_ids = [doc_id for doc_id in collection.get()['ids'] if doc_id.startswith(doc_id_prefix)]\n",
        "#     collection.delete(ids=existing_doc_ids)\n",
        "\n",
        "#     # Load the updated text from the PDF\n",
        "#     updated_text = load_text_from_pdf(pdf_path)\n",
        "\n",
        "#     # Chunk the updated text\n",
        "#     updated_chunks = chunk_text(updated_text)\n",
        "\n",
        "#     # Create new IDs for the updated chunks\n",
        "#     updated_ids = [f\"{doc_id_prefix}_{i}\" for i in range(len(updated_chunks))]\n",
        "\n",
        "#     # Add the updated chunks to the collection\n",
        "#     collection.add(ids=updated_ids, documents=updated_chunks)\n",
        "#     print(f\"Document with prefix {doc_id_prefix} has been updated.\")\n",
        "def update_pdf_in_collection(delete_pdf_path,update_pdf_path):\n",
        "    filename = os.path.basename(delete_pdf_path).replace(\".pdf\", \"\")\n",
        "\n",
        "    # Delete existing chunks for the document\n",
        "    existing_doc_ids = [doc_id for doc_id in collection.get()['ids'] if doc_id.startswith(filename)]\n",
        "    print(existing_doc_ids)\n",
        "    collection.delete(ids=existing_doc_ids)\n",
        "\n",
        "    # Load the updated text from the PDF\n",
        "    updated_text = load_text_from_pdf(update_pdf_path)\n",
        "\n",
        "    # Chunk the updated text\n",
        "    updated_chunks = chunk_text(updated_text)\n",
        "    filename = os.path.basename(update_pdf_path).replace(\".pdf\", \"\")\n",
        "    # Create new IDs for the updated chunks\n",
        "    updated_ids = [f\"{filename}_{i}\" for i in range(len(updated_chunks))]\n",
        "\n",
        "    # Add the updated chunks to the collection\n",
        "    collection.add(ids=updated_ids, documents=updated_chunks)\n",
        "    print(f\"Document with prefix {filename} has been updated.\")\n",
        "\n",
        "# Example of updating the content of the first PDF\n",
        "# update_pdf_path = \"/content/sample_data/g7.pdf\"\n",
        "# update_pdf_in_collection(update_pdf_path, \"1\")\n",
        "update_pdf_path = \"/content/sample_data/g7.pdf\"\n",
        "delete_pdf_path = \"/content/sample_data/105InvestmentPolicyStatement.pdf\"\n",
        "update_pdf_in_collection(delete_pdf_path,update_pdf_path)\n",
        "\n",
        "# # Print the contents of the collection after update\n",
        "# print(\"Contents after update:\")\n",
        "# print_collection_contents()\n",
        "\n",
        "# Print the updated number of documents in the collection\n",
        "print(\"After update, there are\", langchain_chroma._collection.count(), \"documents in the collection\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bUTnPxdpKgh",
        "outputId": "7b12aa3b-9a97-4d19-903f-c785e83ece4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['105InvestmentPolicyStatement_0', '105InvestmentPolicyStatement_1', '105InvestmentPolicyStatement_10', '105InvestmentPolicyStatement_11', '105InvestmentPolicyStatement_12', '105InvestmentPolicyStatement_13', '105InvestmentPolicyStatement_14', '105InvestmentPolicyStatement_15', '105InvestmentPolicyStatement_16', '105InvestmentPolicyStatement_17', '105InvestmentPolicyStatement_18', '105InvestmentPolicyStatement_19', '105InvestmentPolicyStatement_2', '105InvestmentPolicyStatement_20', '105InvestmentPolicyStatement_21', '105InvestmentPolicyStatement_22', '105InvestmentPolicyStatement_23', '105InvestmentPolicyStatement_24', '105InvestmentPolicyStatement_25', '105InvestmentPolicyStatement_26', '105InvestmentPolicyStatement_27', '105InvestmentPolicyStatement_28', '105InvestmentPolicyStatement_29', '105InvestmentPolicyStatement_3', '105InvestmentPolicyStatement_30', '105InvestmentPolicyStatement_31', '105InvestmentPolicyStatement_32', '105InvestmentPolicyStatement_33', '105InvestmentPolicyStatement_34', '105InvestmentPolicyStatement_35', '105InvestmentPolicyStatement_36', '105InvestmentPolicyStatement_37', '105InvestmentPolicyStatement_38', '105InvestmentPolicyStatement_39', '105InvestmentPolicyStatement_4', '105InvestmentPolicyStatement_40', '105InvestmentPolicyStatement_41', '105InvestmentPolicyStatement_42', '105InvestmentPolicyStatement_43', '105InvestmentPolicyStatement_44', '105InvestmentPolicyStatement_45', '105InvestmentPolicyStatement_46', '105InvestmentPolicyStatement_47', '105InvestmentPolicyStatement_48', '105InvestmentPolicyStatement_5', '105InvestmentPolicyStatement_6', '105InvestmentPolicyStatement_7', '105InvestmentPolicyStatement_8', '105InvestmentPolicyStatement_9']\n",
            "Document with prefix g7 has been updated.\n",
            "After update, there are 97 documents in the collection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NExeoyn5pKWg",
        "outputId": "311dcca1-7967-40e6-e8dd-709be6adb8df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['g7_0',\n",
              "  'g7_1',\n",
              "  'g7_10',\n",
              "  'g7_11',\n",
              "  'g7_12',\n",
              "  'g7_13',\n",
              "  'g7_14',\n",
              "  'g7_15',\n",
              "  'g7_16',\n",
              "  'g7_17',\n",
              "  'g7_18',\n",
              "  'g7_19',\n",
              "  'g7_2',\n",
              "  'g7_20',\n",
              "  'g7_21',\n",
              "  'g7_22',\n",
              "  'g7_23',\n",
              "  'g7_24',\n",
              "  'g7_25',\n",
              "  'g7_26',\n",
              "  'g7_27',\n",
              "  'g7_28',\n",
              "  'g7_29',\n",
              "  'g7_3',\n",
              "  'g7_30',\n",
              "  'g7_31',\n",
              "  'g7_32',\n",
              "  'g7_33',\n",
              "  'g7_34',\n",
              "  'g7_35',\n",
              "  'g7_36',\n",
              "  'g7_37',\n",
              "  'g7_38',\n",
              "  'g7_39',\n",
              "  'g7_4',\n",
              "  'g7_40',\n",
              "  'g7_41',\n",
              "  'g7_42',\n",
              "  'g7_43',\n",
              "  'g7_44',\n",
              "  'g7_45',\n",
              "  'g7_46',\n",
              "  'g7_47',\n",
              "  'g7_48',\n",
              "  'g7_5',\n",
              "  'g7_6',\n",
              "  'g7_7',\n",
              "  'g7_8',\n",
              "  'g7_9',\n",
              "  'llama2_removed_0',\n",
              "  'llama2_removed_1',\n",
              "  'llama2_removed_10',\n",
              "  'llama2_removed_11',\n",
              "  'llama2_removed_12',\n",
              "  'llama2_removed_13',\n",
              "  'llama2_removed_14',\n",
              "  'llama2_removed_15',\n",
              "  'llama2_removed_16',\n",
              "  'llama2_removed_17',\n",
              "  'llama2_removed_18',\n",
              "  'llama2_removed_19',\n",
              "  'llama2_removed_2',\n",
              "  'llama2_removed_20',\n",
              "  'llama2_removed_21',\n",
              "  'llama2_removed_22',\n",
              "  'llama2_removed_23',\n",
              "  'llama2_removed_24',\n",
              "  'llama2_removed_25',\n",
              "  'llama2_removed_26',\n",
              "  'llama2_removed_27',\n",
              "  'llama2_removed_28',\n",
              "  'llama2_removed_29',\n",
              "  'llama2_removed_3',\n",
              "  'llama2_removed_30',\n",
              "  'llama2_removed_31',\n",
              "  'llama2_removed_32',\n",
              "  'llama2_removed_33',\n",
              "  'llama2_removed_34',\n",
              "  'llama2_removed_35',\n",
              "  'llama2_removed_36',\n",
              "  'llama2_removed_37',\n",
              "  'llama2_removed_38',\n",
              "  'llama2_removed_39',\n",
              "  'llama2_removed_4',\n",
              "  'llama2_removed_40',\n",
              "  'llama2_removed_41',\n",
              "  'llama2_removed_42',\n",
              "  'llama2_removed_43',\n",
              "  'llama2_removed_44',\n",
              "  'llama2_removed_45',\n",
              "  'llama2_removed_46',\n",
              "  'llama2_removed_47',\n",
              "  'llama2_removed_5',\n",
              "  'llama2_removed_6',\n",
              "  'llama2_removed_7',\n",
              "  'llama2_removed_8',\n",
              "  'llama2_removed_9'],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None,\n",
              "  None],\n",
              " 'documents': ['1 \\n G7 Japan 2023  \\n Foreign Ministers’ Statement   \\nNovember 8 , 2023 , Tokyo  \\n \\nWe, the G7 Foreign Ministers of Canada, France, G ermany, Italy, Japan, the United Kingdom  \\nand the United States of America, and the High Representative of the European Union,  are more \\nunited than ever in the pursuit of  international peace , securit y, and prosperity . In this Foreign \\nMinisters’ Meeti ng, we further enhance our cooperation to collectively respond to recent global and',\n",
              "  'regional issues, building on our commitments by our leaders at  the G7 Hiroshima Summit.  We remain \\nsteadfast in  upholding and strengthening  the free and open international o rder based on the rule of \\nlaw, respecting the United Nations (UN) Charte r. We reiterate our strong opposition to any unilateral \\nattempts to change the peacefully established status of territories by force or coercion anywhere in',\n",
              "  'term solutions for Gaza  and a return to a broader peace process in line with the internationally agreed \\nparameters . We underscore that a two -state solution , which envisions Israel and a  viable Palestinian \\nstate living side by side in peace , security , and mutual recognition,  remains the only  path to a just , \\nlasting , and secure  peace.  \\n \\n2. Russia’s War of Aggression against Ukraine  \\nOur steadfast commitment to supporting Ukraine ’s fight for its independence, sovereignty,',\n",
              "  'and territorial integrity  will never waver . We continue to condemn in the strongest possible terms \\nRussia’s ongoing aggression , and we commit to standing by Ukraine for as long as it takes , while \\nincreasing economic pressure and  imposing robust sanctions and other restrictions against Russia.  A \\njust and lasting peace cannot be realized without the immediate, complete, and unconditional',\n",
              "  'withdrawal of Russia ’s troops and military equipment from the i nternationally recognized territory of \\nUkraine. We continue to support Ukraine in further develop ing President Volodymyr Zelenskyy’s \\nPeace Formula . We are increas ing our efforts to help Ukraine meet its winter preparedness needs, \\nincluding by continuing to provid e critical energy assistance.  \\nRussia’s irresponsible nuclear rhetoric and its announced  deploy ment of  nuclear weapons in',\n",
              "  'Belarus are unacceptable.  Any use of  chemical, biological, or nuclear weapons by Russia would be \\nmet with severe consequences.  We deeply regret  Russia’s decision to revoke  its ratification of the \\nComprehensive Nuclear -Test-Ban Treaty. We strongly support the International Atomic Energy \\nAgency’s (IAEA) continued presence and unfettered access at all of  Ukraine’s civil nuclear  sites. We',\n",
              "  'will reinforce our coordination on sanctions  to restrict Russia ’s access to critical goods and technology. \\nWe will  take further action to prevent the evasion and circumvention of our measures against Russia . \\nWe reiter ate our call for third parties to immediately cease providing material support to Russia’s \\naggression, o r face severe costs.  In order to reduce the revenues that Russian extracts from its export s, 3',\n",
              "  'we will accelerate  our consultation  on energy, metals, and all non -industrial diamonds, including those \\nmined, processed or produced in R ussia.  \\nRussia must cease its aggression and must bear the legal consequences of all its \\ninternationally wrongful acts, including compensation for the damage caused to Ukraine. We are \\nunited in our determination to ensure full accountability. In light of the urgen cy of disrupting Russia’s',\n",
              "  'attempts to destroy the Ukrainian economy and Russia’s continued failure to abide by its international \\nlaw obligations, we are exploring all possible avenues to aid Ukraine, consistent with our respective \\nlegal systems and interna tional law.  We reaffirm that, consistent with our respective legal systems, \\nRussia’s sovereign assets in our jurisdictions will remain immobilized until Russia pays for the damage',\n",
              "  'it has caused to Ukraine. We reiterate our commitment to holding those respo nsible to account \\nconsistent with international law , including by supporting the efforts of international mechanisms, \\nsuch as  the International Criminal Court . \\nWe recommit to supporting Ukraine’s immediate,  medium , and  long -term recovery and \\nreconstruction  in the face of Russia’s efforts to  inflict immense suffering on the people of Ukraine. We',\n",
              "  'are also working  to involve our private sector s in the sustainable economic recovery of Ukraine . We \\nwelcome and  underscore the significance of Ukraine itself continuing to implement domestic reform \\nefforts, especially in the fields of anti -corruption, justice system reform , decentralization , and \\npromotion of the rule of law , in line with the European  path  that Ukraine has embraced together with',\n",
              "  'other partners, including Moldova, Georgia , as well as  countries in the West ern Balkans . We will \\ncontinue to support efforts of the Ukrainian government and people in th ese endeavor s. We will each \\nadvance , in close coordination,  our work with Ukraine on specific, bilateral, long -term  security \\ncommitments and arrangements  in line with the G7 Leaders’ Joint Declaration of Support for Ukraine, \\nwhich now has 31 signatories .',\n",
              "  'the world.  Such attempts un dermine the rule of law, which protects all nations , especially the \\nvulnerable , as well as global  security and human  dignity. We also commit to further building  \\ninternational solidarity beyond the G7 to advance global economic development and address broader \\nglobal challenges, such as  climate change, nuclear disarmament, economic resilience and economic \\nsecurity, and gender equality including the  Women, Peace and Security agenda.  We remain deeply',\n",
              "  'which now has 31 signatories . \\n We reaffirm our commitment to address the growing needs of vulnerable countries  and \\npopulations impacted by Russia’s aggression . Russia’s weaponization of food has compounded \\neconomic vulnerabilities, exacerbated already dire humanitarian crises, and escalated global food \\ninsecurity and malnutriti on worldwide . We deplore Russia’s systematic targeting of Ukrainian Black',\n",
              "  'Sea Ports and civilian infrastructure and welcome steps by Ukraine to strengthen export routes free \\nof Russian control . We continue to support fully the export of Ukrainian agriproducts , including \\nthrough the EU -Ukraine Solidarity Lanes , Danube ports,  and its humanitarian maritime corridor . We \\nreaffirm our aim to limit Russia’s energy revenues and future extractive capabilities , building on the',\n",
              "  'measures we have taken so far . We continue to  reduce our reliance on Russian energy, so that Russia \\nis no longer able to weaponize its energy resources against us. We commit to working with nations \\naround the world to enhance global food and energy security.  \\n \\n3. Indo -Pacif ic and the Region  \\n Together with regional partners, including ASEAN and its Member States, South Asian 4 \\n countries as well as the Pacific Island countries, w e will continue our endeavors towards  a free and',\n",
              "  'open Indo -Pacific, which is inclusive, prosperous, secure, and based on the rule of law, and that \\nprotects shared principles. We reaffirm our unwavering support for ASEAN centrality and unity.  We \\ncontinue to promote cooperation  in line with the  ASEAN Outlook on the Indo -Pacific  and the Pacific \\nIslands Forum’s 2050 Strategy for the Blue Pacific Continent respectively.  We reiterate our',\n",
              "  'commitment to support sustainable, inclusive, resilient and quality infrastructure in partner countries \\nthrough t he G7 Partnership for Global Infrastructure and Investment.  \\n We welcome Japan’s  safe, transparent, and science -based process , including the continued \\nmonitoring of the situation , to responsibly manage the discharge of Advanced Liquid Processing \\nSystem treated water in proactively coordinating with scientists and partners , particularly across the',\n",
              "  'Indo -Pacific region , as well as with the IAEA. We acknowledge the reported  monitoring results  after \\neach discharge  to date , showing that the concentration of nuclides  including tritium  in sea water  and \\nmarine products are far below internationally recognized standard s. \\n We strongly condemn North Korea’s continuing build -up of its unlawful weapons of mass \\ndestruction  (WMD)  and ballistic missile programs . We reiterate our call for the complete',\n",
              "  'denuclearization of the Korean Peninsula  and demand that North Korea  abandon its nuclear weapons, \\nexisting nuclear programs, and any other WMD and ballistic missile programs in a complete, verifiable, \\nand irreversible manner  in accordance  with all relevant UN Security Council resolutions (UNSCRs).  We \\ncall on all UN Member States to fully and effectively implement all relevant UNSCRs and urge UNSC \\nmembers to follow through on their commitments. In this context, we strongly condemn arms',\n",
              "  'transfer s from North Korea to Russia, which directly violate  relevant UNSCRs. We urge Russ ia and \\nNorth Korea to immediately cease all such activities. We deplore North Korea’s systematic human \\nrights violations and its choice to prio ritize its unlawful WMD and ballistic missile programs over the \\nwelfare of the people in North Korea.  We also urge North Korea to resolve the abduction s issue \\nimmediately.  \\n \\n4. China',\n",
              "  'immediately.  \\n \\n4. China  \\n We stand prepared to build constructive and stable relations with China, recognizing the \\nimportance of engaging candidly and expressing our concerns directly to China . We act in our national \\ninterest s. We acknowledge the need to work together with China on global challenges as well as areas \\nof common interest , and  call on China to engage with us  on these issues . Our policy approaches are',\n",
              "  'not designed to harm China nor do  we seek to thwart China’s economic progress and development. \\nWe are not decoupling or turning inward s. At the same time, we recognize that economic resilience \\nrequires de -risking and diversifying. With a view to enabling sustainable economic relations wit h \\nChina, and strengthening the international trading system, we will continue to push for a level playing',\n",
              "  'concerned about foreign interference, information manipulation, and other hostile actions designed \\nto undermine our democracies . We call on all countries to respect their obligations under the Vienna \\nConvention on Diplomatic Relations. We underscore the ne ed to advance  all of the Sustainable \\nDevelopment Goals  to promote peace and prosperity for people and the planet , as reflected at the \\n2023 SDG Summit. We also take note of  the Summit for a New Global Financing Pact. Our',\n",
              "  \"field for our workers and companies. We will seek to address the challenges posed by China's non -\\nmarket policies and practices, which distort the glob al economy. We will counter malign practices, 5 \\n such as illegitimate technology transfer or data disclosure.  We will foster resilience to economic \\ncoercion. We also recognize the necessity of protecting certain advanced technologies that could be\",\n",
              "  'used to thr eaten our national security without unduly limiting trade and investment. We call on China \\nto act as a responsible member of the international community. In this regard, we welcome  China’s \\nparticipation in the Ukraine -led peace process . We further  call on China  not to assist Russia in its war \\nagainst Ukraine, to press Russia to stop its military aggression , and to support a just and lasting peace \\nin Ukraine.',\n",
              "  'in Ukraine.  \\n We underscore that Chin a has a responsibility to uphold the purposes and principles of the \\nUN Charter in their  entirety. We remain seriously concerned about the situation in the East and South \\nChina Sea s, strongly opposing  any unilateral attempts to change the status quo by force or coercion . \\nWe reemphasize the universal and unified character of the  United Nations Convention on the Law of',\n",
              "  'the Sea  (UNCLOS ) and reaffirm UNCLOS ’s important role in setting  out the legal framewo rk that \\ngoverns all activities in the oceans and the seas. We reiterate that the award rendered by the Arbitral \\nTribunal on July 12, 2016, is a significant milestone, which is legally binding upon the parties to those \\nproceedings, and a useful basis for pe acefully resolving disputes between the parties.  \\nWe reaffirm the importance of peace and stability across the Taiwan Strait as indispensable',\n",
              "  'to security and prosperity in the international community and call for the peaceful resolution of cross -\\nStrait iss ues. There is no change in the basic position of the G7 members on Taiwan, including stated \\none China policies. We reiterate our support for Taiwan’s meaningful participation in international \\norganizations , including in the World Health Assembly and WHO te chnical meetings . We also remain',\n",
              "  'concerned about the human rights situation in China, including in Xinjiang and Tibet. We further call \\non China to uphold its commitments under the Sino -British Joint Declaration and the Basic Law , which \\nenshrine rights and freedoms and a high degree of autonomy for Hong Kong . We call on China to act \\nin accordance with its obligations under the Vienna Convention on Diplomatic Relations and the \\nVienna Convention on Consular Relations  and not to conduct interference activities, aimed at',\n",
              "  'undermining the security and safety of our communities, the integrity of our democratic institutions , \\nand our economic prosperity . \\n \\n5. Central Asia  and South Caucasus  \\nWe remain resolved to support the sovereignty, independence, and territorial integrity of \\nCentral Asian countries . We welcome the intensification of regional cooperation  and people -to-\\npeople links , which can boost creation of more business opportunities and new innovations . We',\n",
              "  'renew our determination to strengthen cooperation with  Central Asian countries  to address regional \\nchallenges , including the global consequences of Russia’s war of aggression, the destabilizing effect \\nof the situation in Afghanistan , including  the human rights violations  by the Taliban , terrorism, water \\nsecurity, and climate change.  Against the backdrop of  growing geopolitical risk , the diversification and',\n",
              "  'expansion of trade routes in Central Asian countries not only brings economic growth  to the region, 6 \\n but also has potential to improve  global supply chain s, including energy security. In this regard, w e \\nrecommit to fostering trade and energy links, sustainable  connectivity and transportation,  including \\nthe Middle Corridor, and associated projects to enhance regional r esilience.  We also recommit to',\n",
              "  'supporting socio -economic and political reform efforts in Central Asian countries . \\nWe are gravely concern ed over the humanitarian consequences of  the displacement of \\nArmenians  from Nagorno -Karabakh  after the military operation conducted by Azerbaijan . We urge \\nAzerbaijan to fully comply with its obligations under international humanitarian law and welcome \\ninternational efforts to  address urgent humanitarian needs  for those who have been displaced . We',\n",
              "  'determination to meet our  commitments on these issues is unwavering , and we will continue \\nstrengthen ing them  towards the next year under the Italian Presidency.   \\n \\n1. Situation in Israel , Gaza , and the West Bank  \\nWe unequivocally condemn the terror attacks by Hamas and other s across Israel  that began \\non October 7, 2023 , as well as ongoing missile attacks against Israel . We emphasize Israel ’s right to',\n",
              "  'underline our support for advancing a sustainable and lasting peace between Armenia and Azerbaijan \\nbased on the principles of non-use of force, respect for sovereignty, the inviolability of borders, and \\nterritorial integrity . \\n \\n6. Iran  \\n We call on Iran to refrain from providing support for Hamas and taking further actions that \\ndestabilize the Middle East, including support for Lebanese Hezbollah and other non-state  actors , and',\n",
              "  'to use its influence with those  groups to  de-escalat e regional tensions.  \\nWe remain determined that Iran must never develop a nuclear weapon and reiterate  that \\nIran must cease its unabated escalation of its nuclear program , which has no credible civilian \\njustification and brings it dangerously clo se to actual weapon -related activities . We call on Iran to \\nfulfill its legal obligations and political commitments regarding nuclear non -proliferation with prompt',\n",
              "  'action , including the full and unconditional cooperation with the IAEA. We urge Iran to rever se the \\nde-designations of the IAEA inspectors, which affects in a severe way the Agency’s ability to conduct  \\neffectively  its inspections in Iran . A diplomatic solution remains the best way to resolve international \\nconcerns.  \\nWe express our grave concern regarding Iran’s other destabilizing activities, such as  the',\n",
              "  'development of ballistic missile programs, including under the guise of  space launch ve hicle s, transfer \\nof missiles, unmanned aerial vehicles and related technologies to state and non -state actors , as well \\nas training and funding of non -state actors . Iran must stop supporting Russia’ s war of aggression  \\nagainst Ukraine . Furthermore, we emphasize the importance of ensuring maritime security in the',\n",
              "  'wider Gulf region ’s waterways and call on Iran not to interfere with the lawful exercise of navigational \\nrights and freedoms by all vessels .  \\nWe also express deep concern over th e deteriorati ng human rights situation in Iran , including \\nfor women, girls, and minority groups,  and condemn the targeting of individuals  outside of Iran , \\nincluding journalists and dissidents . \\n \\n7. Africa  \\nWe remain steadfast in our commitment to deepening partnerships with African countries 7',\n",
              "  'and regional and continental organizations. We welcom e the  African Union (AU) as a permanent \\nmember of the G20  as reflected  in the G20 New Delhi Leaders’ Declaration . We will continue to \\nsupport stronger African  representation in other international fora, including the UNSC . We welcome \\nthe role of the AU and Regional Economic Communities and Mechanisms in promoting Agenda 2063 \\nand mediating disputes and con flict. We express our concern over the deteriorating political, security,',\n",
              "  'and humanitarian situation in some parts of the continent . We reiterate our commitment to support \\nthe preserv ation of  peace, stability, and good governance and to promote sustainable growth and \\ndevelopment in the entire ty of Africa. We will continue  to support governments in the region to tackle \\nthe underlying conditions conducive to the spread of conflict, terrorism, violent extremism, instab ility,',\n",
              "  'persecution,  irregular migration , and human suffering . We call for parties to conflicts to respect \\ninternational humanitarian law and international human rights law; for safe, unhindered  access for \\nhumanitarian actors to reach those in need ; and for those responsible for atrocities committed during \\narmed conflict to be he ld to account . \\nWe reiterate our support to the UN in their efforts to advance  the Libyan political process in',\n",
              "  'order to  hold  genuine, free, fair , and inclusive  elections without further delays.  We encourage Tunisia \\nto implement reforms  in order to enhance its economic and  institutional stability.  \\n(End)',\n",
              "  'defend itself and its people , in accordance with international law , as it seeks to prevent a recurrence . \\nWe call for the immediate release of all hostages without precondition s. We express our deepest \\nsympathy and condolences to the victims of thes e attacks and their families , as well as  all civilians, \\nPalestinian, Israeli, and others , including our own citizens,  who have died or been injured during this',\n",
              "  'conflict . Israelis and Palestinians have an equal  right to live in safety, dignity, and peace. We reject \\nantisemitism and Islamophobia i n any form in our own societies  and anywhere in the world.  \\nWe stress the need for urgent  action to address  the deteriorating humanitarian crisis  in Gaza. \\nAll parties  must allow uni mpeded  humanitarian support  for civilians , including  food, water, medical',\n",
              "  'care, fuel, and shelter, and access for humanitarian workers . We support humanitarian pauses and 2 \\n corridors to facilitate urgently needed assistance, civilian movement, and the release of hostages . \\nForeign nationals must also be allowe d to continue to depart. We underscore the importance of \\nprotecting civilians and compliance with i nternational law, in particular international humanitarian',\n",
              "  'law. Since October  7, the G7 members have p ledged an additional $500 million  for the Palestinian \\npeople, including t hrough the UN agencies  and other humanitarian actors.  We urge countries around \\nthe world to join us in this effort.  We welcome the November 9 international conference in Paris on \\nhumanitarian  issues.  \\nThe rise in extremist settler violence committed against Palestinians is unacceptable ,',\n",
              "  'undermines security in the West Bank , and threatens prospects for a lasting peace.  The G7 members, \\nalong with partners in the region , are working intensively to  prevent the conflict from escalating \\nfurther and spreading more widely . We are also working together , including by imposing sanctions or \\nother measures,  to deny Hamas the ability to raise and use funds to carry out atrocities.   \\nThe G7 members  are committed to work ing closely with partners to prepare sustainable long -',\n",
              "  'Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev',\n",
              "  'Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic',\n",
              "  'canbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in',\n",
              "  'ties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive',\n",
              "  'chat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave',\n",
              "  'limited the development of LLMs to a few players. There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such',\n",
              "  'asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and',\n",
              "  'Llama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata',\n",
              "  'annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas',\n",
              "  'the emergence of tool usage and temporal organization of knowledge.\\n3 Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe',\n",
              "  'promptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and',\n",
              "  'adoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,',\n",
              "  'Sergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-',\n",
              "  'Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse',\n",
              "  'guide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/',\n",
              "  '§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4 Figure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning',\n",
              "  'with Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.',\n",
              "  '(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data',\n",
              "  '2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.',\n",
              "  'knowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and',\n",
              "  'Sennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=',\n",
              "  '0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5 Training Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly',\n",
              "  'Llama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.\\n0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B',\n",
              "  'source models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023 Contents\\n1 Introduction 3\\n2 Pretraining 5',\n",
              "  '7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,',\n",
              "  'we split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum',\n",
              "  'InfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6 Time\\n(GPU hours)Power',\n",
              "  '6 Time\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing',\n",
              "  'these models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon',\n",
              "  'efficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction',\n",
              "  'of AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s',\n",
              "  'sustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.\\n2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.',\n",
              "  'For all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.',\n",
              "  '•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.',\n",
              "  '1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9',\n",
              "  '•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.',\n",
              "  '(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7 Model Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9',\n",
              "  'Llama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.',\n",
              "  '•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023). For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B',\n",
              "  'modelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant',\n",
              "  'gaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8',\n",
              "  'GSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,',\n",
              "  'including both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8',\n",
              "  '3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20',\n",
              "  '4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32',\n",
              "  '5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47',\n",
              "  'A.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75',\n",
              "  'A.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2 Figure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations'],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents']}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UV6qSfRWu_pr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}