{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "67c8afd7",
      "metadata": {
        "id": "67c8afd7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/multi_document_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43497beb-817d-4366-9156-f4d7f0d44942",
      "metadata": {
        "id": "43497beb-817d-4366-9156-f4d7f0d44942"
      },
      "source": [
        "# Multi-Document Agents\n",
        "\n",
        "In this guide, you learn towards setting up an agent that can effectively answer different types of questions over a larger set of documents.\n",
        "\n",
        "These questions include the following\n",
        "\n",
        "- QA over a specific doc\n",
        "- QA comparing different docs\n",
        "- Summaries over a specific doc\n",
        "- Comparing summaries between different docs\n",
        "\n",
        "We do this with the following architecture:\n",
        "\n",
        "- setup a \"document agent\" over each Document: each doc agent can do QA/summarization within its doc\n",
        "- setup a top-level agent over this set of document agents. Do tool retrieval and then do CoT over the set of tools to answer a question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be00aba-b6c5-4940-9825-81c5d2cd2f0b",
      "metadata": {
        "id": "9be00aba-b6c5-4940-9825-81c5d2cd2f0b"
      },
      "source": [
        "## Setup and Download Data\n",
        "\n",
        "In this section, we'll define imports and then download Wikipedia articles about different cities. Each article is stored separately.\n",
        "\n",
        "We load in 18 cities - this is not quite at the level of \"hundreds\" of documents but its still large enough to warrant some top-level document retrieval!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d81f93c",
      "metadata": {
        "id": "5d81f93c"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4110483a",
      "metadata": {
        "id": "4110483a",
        "outputId": "c3d50472-c0ec-49a0-a155-3859ce98f63e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-agent-openai\n",
            "  Downloading llama_index_agent_openai-0.2.8-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.41 (from llama-index-agent-openai)\n",
            "  Downloading llama_index_core-0.10.55-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index-agent-openai)\n",
            "  Downloading llama_index_llms_openai-0.1.25-py3-none-any.whl (11 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai)\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (8.4.2)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.14.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai) (1.3.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2024.5.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.14.0->llama-index-agent-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.14.0->llama-index-agent-openai) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-agent-openai) (1.16.0)\n",
            "Installing collected packages: dirtyjson, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, llama-index-llms-openai, llama-index-agent-openai\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-agent-openai-0.2.8 llama-index-core-0.10.55 llama-index-llms-openai-0.1.25 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.35.13 tiktoken-0.7.0 typing-inspect-0.9.0\n",
            "Collecting llama-index-embeddings-openai\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai) (0.10.55)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.35.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.4.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
            "Installing collected packages: llama-index-embeddings-openai\n",
            "Successfully installed llama-index-embeddings-openai-0.1.10\n",
            "Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.10/dist-packages (0.1.25)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (0.10.55)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.35.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.4.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-agent-openai\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-llms-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f0fb1340",
      "metadata": {
        "id": "f0fb1340",
        "outputId": "a386ecdf-118e-4548-ead4-08e0f864de56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.55-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.8)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: llama-index-core==0.10.55 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.55)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.10)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.5-py3-none-any.whl (9.3 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.25)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl (5.9 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.30-py3-none-any.whl (38 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.35.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (8.4.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.14.1)\n",
            "Collecting llama-cloud>=0.0.9 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.9-py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.4.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.9->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.55->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.55->llama-index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.55->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.55->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.55->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.55->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.55->llama-index) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.55->llama-index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.55->llama-index) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.9->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.9->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.55->llama-index) (1.16.0)\n",
            "Installing collected packages: striprtf, pypdf, llama-cloud, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed llama-cloud-0.0.9 llama-index-0.10.55 llama-index-cli-0.1.12 llama-index-indices-managed-llama-cloud-0.2.5 llama-index-legacy-0.9.48 llama-index-multi-modal-llms-openai-0.1.7 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.30 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.6 pypdf-4.2.0 striprtf-0.0.26\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e41e9905-77a9-44c5-88ac-c7a4d08a4612",
      "metadata": {
        "id": "e41e9905-77a9-44c5-88ac-c7a4d08a4612"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleKeywordTableIndex,\n",
        "    SimpleDirectoryReader,\n",
        ")\n",
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.core.schema import IndexNode\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.callbacks import CallbackManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e4343cf7-eec9-4a67-b5be-c72dbe3280a7",
      "metadata": {
        "id": "e4343cf7-eec9-4a67-b5be-c72dbe3280a7"
      },
      "outputs": [],
      "source": [
        "wiki_titles = [\n",
        "    \"Toronto\",\n",
        "    \"Seattle\",\n",
        "    \"Chicago\",\n",
        "    \"Boston\",\n",
        "    \"Houston\",\n",
        "    \"Tokyo\",\n",
        "    \"Berlin\",\n",
        "    \"Lisbon\",\n",
        "    \"Paris\",\n",
        "    \"London\",\n",
        "    \"Atlanta\",\n",
        "    \"Munich\",\n",
        "    \"Shanghai\",\n",
        "    \"Beijing\",\n",
        "    \"Copenhagen\",\n",
        "    \"Moscow\",\n",
        "    \"Cairo\",\n",
        "    \"Karachi\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6d261882-6793-4eca-ad93-d94d2061e388",
      "metadata": {
        "id": "6d261882-6793-4eca-ad93-d94d2061e388"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "for title in wiki_titles:\n",
        "    response = requests.get(\n",
        "        \"https://en.wikipedia.org/w/api.php\",\n",
        "        params={\n",
        "            \"action\": \"query\",\n",
        "            \"format\": \"json\",\n",
        "            \"titles\": title,\n",
        "            \"prop\": \"extracts\",\n",
        "            # 'exintro': True,\n",
        "            \"explaintext\": True,\n",
        "        },\n",
        "    ).json()\n",
        "    page = next(iter(response[\"query\"][\"pages\"].values()))\n",
        "    wiki_text = page[\"extract\"]\n",
        "\n",
        "    data_path = Path(\"data\")\n",
        "    if not data_path.exists():\n",
        "        Path.mkdir(data_path)\n",
        "\n",
        "    with open(data_path / f\"{title}.txt\", \"w\") as fp:\n",
        "        fp.write(wiki_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5bf0c13b-0d77-43e8-8c1c-84258299a494",
      "metadata": {
        "id": "5bf0c13b-0d77-43e8-8c1c-84258299a494"
      },
      "outputs": [],
      "source": [
        "# Load all wiki documents\n",
        "city_docs = {}\n",
        "for wiki_title in wiki_titles:\n",
        "    city_docs[wiki_title] = SimpleDirectoryReader(\n",
        "        input_files=[f\"data/{wiki_title}.txt\"]\n",
        "    ).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# city_docs"
      ],
      "metadata": {
        "id": "03pNYdHzmKlK"
      },
      "id": "03pNYdHzmKlK",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6189aaf4-2eb7-40bc-9e83-79ce4f221b4b",
      "metadata": {
        "id": "6189aaf4-2eb7-40bc-9e83-79ce4f221b4b"
      },
      "source": [
        "Define Global LLM and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dd6e5e48-91b9-4701-a85d-d98c92323350",
      "metadata": {
        "id": "dd6e5e48-91b9-4701-a85d-d98c92323350"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eeef31a-fc25-4367-a5ba-945f81d04cf9",
      "metadata": {
        "id": "4eeef31a-fc25-4367-a5ba-945f81d04cf9"
      },
      "source": [
        "## Building Multi-Document Agents\n",
        "\n",
        "In this section we show you how to construct the multi-document agent. We first build a document agent for each document, and then define the top-level parent agent with an object index."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "976cd798-2e8d-474c-922a-51b12c5c6f36",
      "metadata": {
        "id": "976cd798-2e8d-474c-922a-51b12c5c6f36"
      },
      "source": [
        "### Build Document Agent for each Document\n",
        "\n",
        "In this section we define \"document agents\" for each document.\n",
        "\n",
        "We define both a vector index (for semantic search) and summary index (for summarization) for each document. The two query engines are then converted into tools that are passed to an OpenAI function calling agent.\n",
        "\n",
        "This document agent can dynamically choose to perform semantic search or summarization within a given document.\n",
        "\n",
        "We create a separate document agent for each city."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "W2CMJhJU4xTF"
      },
      "id": "W2CMJhJU4xTF",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eacdf3a7-cfe3-4c2b-9037-b28a065ed148",
      "metadata": {
        "id": "eacdf3a7-cfe3-4c2b-9037-b28a065ed148",
        "outputId": "0c0b7ba3-0ad9-4739-c654-782c9a56610f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id cac11eca-04c3-47cb-8bc6-d02641fce0d4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00, 1823.61it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
            "1it [00:00, 7025.63it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
            "3it [00:00, 19753.39it/s]\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n",
            "2it [00:00, 15709.00it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n",
            "1it [00:00, 8981.38it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
            "3it [00:00, 21583.04it/s]\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n",
            "4it [00:00, 7297.61it/s]\n",
            "100%|██████████| 4/4 [00:01<00:00,  2.02it/s]\n",
            "1it [00:00, 1598.44it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "1it [00:00, 9000.65it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 08ad156e-b32c-419b-a6e5-82e6ff0e7fbe\n",
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00, 9341.43it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
            "1it [00:00, 5637.51it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
            "1it [00:00, 1575.62it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
            "3it [00:00, 24244.53it/s]\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n"
          ]
        }
      ],
      "source": [
        "from llama_index.agent.openai import OpenAIAgent\n",
        "from llama_index.core import load_index_from_storage, StorageContext\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "import os\n",
        "from llama_parse import LlamaParse\n",
        "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
        "# node_parser = SentenceSplitter()\n",
        "\n",
        "# Build agents dictionary\n",
        "agents = {}\n",
        "query_engines = {}\n",
        "\n",
        "# this is for the baseline\n",
        "all_nodes = []\n",
        "\n",
        "\n",
        "# for idx, wiki_title in enumerate(wiki_titles):\n",
        "#     nodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])\n",
        "#     all_nodes.extend(nodes)\n",
        "\n",
        "#     if not os.path.exists(f\"./data/{wiki_title}\"):\n",
        "#         # build vector index\n",
        "#         vector_index = VectorStoreIndex(nodes)\n",
        "#         vector_index.storage_context.persist(\n",
        "#             persist_dir=f\"./data/{wiki_title}\"\n",
        "#         )\n",
        "#     else:\n",
        "#         vector_index = load_index_from_storage(\n",
        "#             StorageContext.from_defaults(persist_dir=f\"./data/{wiki_title}\"),\n",
        "#         )\n",
        "# Folder containing the PDF files\n",
        "pdf_folder = '/content/pdf_folder'\n",
        "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
        "\n",
        "# Initialize the parser\n",
        "node_parser = MarkdownElementNodeParser(\n",
        "    llm=Settings.llm,\n",
        "    num_workers=8\n",
        ")\n",
        "\n",
        "all_nodes = []\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "    documents = LlamaParse(result_type=\"markdown\").load_data(pdf_path)\n",
        "\n",
        "    nodes = node_parser.get_nodes_from_documents(documents)\n",
        "    all_nodes.extend(nodes)\n",
        "\n",
        "    # Use the PDF file name (without extension) as the identifier\n",
        "    pdf_name = os.path.splitext(pdf_file)[0]\n",
        "\n",
        "    if not os.path.exists(f\"./data/{pdf_name}\"):\n",
        "        # Build vector index\n",
        "        vector_index = VectorStoreIndex(nodes)\n",
        "        vector_index.storage_context.persist(\n",
        "            persist_dir=f\"./data/{pdf_name}\"\n",
        "        )\n",
        "    else:\n",
        "        vector_index = load_index_from_storage(\n",
        "            StorageContext.from_defaults(persist_dir=f\"./data/{pdf_name}\"),\n",
        "        )\n",
        "\n",
        "\n",
        "    # build summary index\n",
        "    summary_index = SummaryIndex(nodes)\n",
        "    # define query engines\n",
        "    vector_query_engine = vector_index.as_query_engine(llm=Settings.llm)\n",
        "    summary_query_engine = summary_index.as_query_engine(llm=Settings.llm)\n",
        "\n",
        "    # define tools\n",
        "    query_engine_tools = [\n",
        "        QueryEngineTool(\n",
        "            query_engine=vector_query_engine,\n",
        "            metadata=ToolMetadata(\n",
        "                name=\"vector_tool\",\n",
        "                description=(\n",
        "                    \"Useful for questions related to specific aspects of\"\n",
        "                    f\" {pdf_name} (e.g. policy key features, policy terms, premium payment mode, sum assured.).\"\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "        QueryEngineTool(\n",
        "            query_engine=summary_query_engine,\n",
        "            metadata=ToolMetadata(\n",
        "                name=\"summary_tool\",\n",
        "                description=(\n",
        "                    \"Useful for any requests that require a holistic summary\"\n",
        "                    f\" of EVERYTHING about {pdf_name}. For questions about\"\n",
        "                    \" more specific sections, please use the vector_tool.\"\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    # build agent\n",
        "    # function_llm = OpenAI(model=\"gpt-4\")\n",
        "    function_llm = Settings.llm\n",
        "    agent = OpenAIAgent.from_tools(\n",
        "        query_engine_tools,\n",
        "        llm=function_llm,\n",
        "        verbose=True,\n",
        "        system_prompt=f\"\"\"\\\n",
        "You are a specialized agent designed to answer queries about {pdf_name}.\n",
        "You must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\n",
        "\"\"\",\n",
        "    )\n",
        "\n",
        "    agents[pdf_name] = agent\n",
        "    query_engines[pdf_name] = vector_index.as_query_engine(\n",
        "        similarity_top_k=2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agents"
      ],
      "metadata": {
        "id": "7sAMiWQYCxyq",
        "outputId": "f46cb7bd-defc-4f84-da66-b9ec25bab9e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7sAMiWQYCxyq",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hdfc-smart-term-insurence': <llama_index.agent.openai.base.OpenAIAgent at 0x7dbd30bbd2d0>,\n",
              " 'max-life-smart-term-insurence': <llama_index.agent.openai.base.OpenAIAgent at 0x7dbd3002ea10>}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engines"
      ],
      "metadata": {
        "id": "6W4GiNGRC2HU",
        "outputId": "23fa613a-6d3a-4411-e0d8-f8336e992a68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6W4GiNGRC2HU",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hdfc-smart-term-insurence': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x7dbd30bbf100>,\n",
              " 'max-life-smart-term-insurence': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x7dbd3002d030>}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all_nodes"
      ],
      "metadata": {
        "id": "98xMB5GVpc6w"
      },
      "id": "98xMB5GVpc6w",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "899ca55b-0c02-429b-a765-8e4f806d503f",
      "metadata": {
        "id": "899ca55b-0c02-429b-a765-8e4f806d503f"
      },
      "source": [
        "### Build Retriever-Enabled OpenAI Agent\n",
        "\n",
        "We build a top-level agent that can orchestrate across the different document agents to answer any user query.\n",
        "\n",
        "This agent takes in all document agents as tools. This specific agent `RetrieverOpenAIAgent` performs tool retrieval before tool use (unlike a default agent that tries to put all tools in the prompt).\n",
        "\n",
        "Here we use a top-k retriever, but we encourage you to customize the tool retriever method!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_files"
      ],
      "metadata": {
        "id": "sa0nfDwE6kKh",
        "outputId": "5dc55e38-a0ce-441c-8ff5-c814ca3ad943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sa0nfDwE6kKh",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hdfc-smart-term-insurence.pdf', 'max-life-smart-term-insurence.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6884ff15-bf40-4bdd-a1e3-58cbd056a12a",
      "metadata": {
        "id": "6884ff15-bf40-4bdd-a1e3-58cbd056a12a"
      },
      "outputs": [],
      "source": [
        "# define tool for each document agent\n",
        "all_tools = []\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_name = os.path.splitext(pdf_file)[0]\n",
        "    pdf_summary = (\n",
        "        f\"This content contains policy details about {pdf_name}. Use\"\n",
        "        f\" this tool if you want to answer any questions about {pdf_name}.\\n\"\n",
        "    )\n",
        "    doc_tool = QueryEngineTool(\n",
        "        query_engine=agents[pdf_name],\n",
        "        metadata=ToolMetadata(\n",
        "            name=f\"tool_{pdf_name}\",\n",
        "            description=pdf_summary,\n",
        "        ),\n",
        "    )\n",
        "    all_tools.append(doc_tool)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tools"
      ],
      "metadata": {
        "id": "F6AoQVjwENfm",
        "outputId": "a43a2149-d517-4516-81a5-b51e21e3fa6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F6AoQVjwENfm",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<llama_index.core.tools.query_engine.QueryEngineTool at 0x7dbd30bd7d60>,\n",
              " <llama_index.core.tools.query_engine.QueryEngineTool at 0x7dbd30bd7cd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "da80793c-54b9-43e2-b34a-27412156268a",
      "metadata": {
        "id": "da80793c-54b9-43e2-b34a-27412156268a"
      },
      "outputs": [],
      "source": [
        "# define an \"object\" index and retriever over these tools\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.objects import ObjectIndex\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    all_tools,\n",
        "    index_cls=VectorStoreIndex,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fed38942-1e37-4c61-89fa-d2ef41151831",
      "metadata": {
        "id": "fed38942-1e37-4c61-89fa-d2ef41151831"
      },
      "outputs": [],
      "source": [
        "from llama_index.agent.openai import OpenAIAgent\n",
        "\n",
        "top_agent = OpenAIAgent.from_tools(\n",
        "    tool_retriever=obj_index.as_retriever(similarity_top_k=3),\n",
        "    system_prompt=\"\"\" \\\n",
        "You are an agent designed to answer queries about a set of policy documents.\n",
        "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
        "\n",
        "\"\"\",\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa32b97c-6779-4b60-823d-6ca3be6f358a",
      "metadata": {
        "id": "aa32b97c-6779-4b60-823d-6ca3be6f358a"
      },
      "source": [
        "### Define Baseline Vector Store Index\n",
        "\n",
        "As a point of comparison, we define a \"naive\" RAG pipeline which dumps all docs into a single vector index collection.\n",
        "\n",
        "We set the top_k = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "78e7b48c-687a-4585-a730-e651212de3b5",
      "metadata": {
        "id": "78e7b48c-687a-4585-a730-e651212de3b5"
      },
      "outputs": [],
      "source": [
        "base_index = VectorStoreIndex(all_nodes)\n",
        "base_query_engine = base_index.as_query_engine(similarity_top_k=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dedb927-a992-4f21-a0fb-4ce4361adcb3",
      "metadata": {
        "id": "8dedb927-a992-4f21-a0fb-4ce4361adcb3"
      },
      "source": [
        "## Running Example Queries\n",
        "\n",
        "Let's run some example queries, ranging from QA / summaries over a single document to QA / summarization over multiple documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8e743c62-7dd8-4ac9-85a5-f1cbc112a79c",
      "metadata": {
        "id": "8e743c62-7dd8-4ac9-85a5-f1cbc112a79c",
        "outputId": "65dbdace-1664-4a2f-cf43-10e30cb50afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the hdfc term insurence policy?\n",
            "=== Calling Function ===\n",
            "Calling function: tool_hdfc-smart-term-insurence with args: {\"input\":\"overview\"}\n",
            "Added user message to memory: overview\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\":\"hdfc-smart-term-insurence\"}\n",
            "Got output: HDFC Life Smart Term Edge is a Non-Linked, Non-Participating Individual Life Term Insurance Plan that offers coverage up to 75 years with the option for a return of premiums up to 150%. It provides different plan variants - Classic, Step-up, and Comprehensive, each with specific details and benefits. The plan allows for customization with additional riders like HDFC Life Accidental Death, Disability and Dismemberment Rider and HDFC Life Critical Illness Rider. Premium payment modes include monthly, half-yearly, and annual options. The plan also outlines terms and conditions related to grace period, lapse, reduced paid-up benefits, surrender value, free look period, suicide clause, and revival policy. It is important to carefully review the policy terms and conditions for a comprehensive understanding of the associated risks and benefits before making a decision to purchase the plan.\n",
            "========================\n",
            "\n",
            "Got output: The HDFC Life Smart Term Edge is a Non-Linked, Non-Participating Individual Life Term Insurance Plan that offers coverage up to 75 years with the option for a return of premiums up to 150%. It provides different plan variants - Classic, Step-up, and Comprehensive, each with specific details and benefits. The plan allows for customization with additional riders like HDFC Life Accidental Death, Disability and Dismemberment Rider and HDFC Life Critical Illness Rider. Premium payment modes include monthly, half-yearly, and annual options. The plan also outlines terms and conditions related to grace period, lapse, reduced paid-up benefits, surrender value, free look period, suicide clause, and revival policy. It is important to carefully review the policy terms and conditions for a comprehensive understanding of the associated risks and benefits before making a decision to purchase the plan.\n",
            "========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# should use Boston agent -> vector tool\n",
        "response = top_agent.query(\"Tell me about the hdfc term insurence policy?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a4ce2a76-5779-4acf-9337-69109dae7fd6",
      "metadata": {
        "id": "a4ce2a76-5779-4acf-9337-69109dae7fd6",
        "outputId": "aaab2683-aab2-4924-dd42-b757b2027cb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The HDFC Life Smart Term Edge is a Non-Linked, Non-Participating Individual Life Term Insurance Plan that offers coverage up to 75 years with the option for a return of premiums up to 150%. It provides different plan variants - Classic, Step-up, and Comprehensive, each with specific details and benefits. The plan allows for customization with additional riders like HDFC Life Accidental Death, Disability and Dismemberment Rider and HDFC Life Critical Illness Rider. Premium payment modes include monthly, half-yearly, and annual options. The plan also outlines terms and conditions related to grace period, lapse, reduced paid-up benefits, surrender value, free look period, suicide clause, and revival policy. It is important to carefully review the policy terms and conditions for a comprehensive understanding of the associated risks and benefits before making a decision to purchase the plan.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "af28b422-fb73-4b59-9e77-3ba3afa87795",
      "metadata": {
        "id": "af28b422-fb73-4b59-9e77-3ba3afa87795",
        "outputId": "6ef6a007-cd3a-4a96-a0c6-76eef25fd057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HDFC Life Smart Term Edge is a Non-Linked Non-Participating Individual Life Term Insurance Plan that offers different variants for desired protection, such as Classic, Step-up, and Comprehensive. It provides a substantial death benefit at affordable premiums and allows for customization with additional riders like Critical Illness and Accident Riders. The policy also offers a return of a percentage of premiums paid on completion of the policy term based on the variant chosen.\n"
          ]
        }
      ],
      "source": [
        "# baseline\n",
        "response = base_query_engine.query(\n",
        "    \"Tell me about the hdfc term insurence policy?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "aa3d98ab-cb82-4473-ab2b-bc8a17e1b86a",
      "metadata": {
        "id": "aa3d98ab-cb82-4473-ab2b-bc8a17e1b86a",
        "outputId": "657d7f7d-dbfb-4137-f03c-9be45c085cc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: HDFC Life Critical Illness Rider can you explain this?\n",
            "=== Calling Function ===\n",
            "Calling function: tool_hdfc-smart-term-insurence with args: {\"input\":\"HDFC Life Critical Illness Rider\"}\n",
            "Added user message to memory: HDFC Life Critical Illness Rider\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\":\"HDFC Life Critical Illness Rider\"}\n",
            "Got output: The HDFC Life Critical Illness Rider provides coverage for critical illnesses, where the rider sum assured is payable in a lump sum upon the diagnosis of any covered critical illness. The benefit amount is based on the terms and conditions of the rider, and it offers additional financial protection in case of such unfortunate occurrences.\n",
            "========================\n",
            "\n",
            "Got output: The HDFC Life Critical Illness Rider provides coverage for critical illnesses, where the rider sum assured is payable in a lump sum upon the diagnosis of any covered critical illness. The benefit amount is based on the terms and conditions of the rider, and it offers additional financial protection in case of such unfortunate occurrences.\n",
            "========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# should use Houston agent -> vector tool\n",
        "response = top_agent.query(\n",
        "    \"HDFC Life Critical Illness Rider can you explain this?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# should use Houston agent -> vector tool\n",
        "response = top_agent.query(\n",
        "    \"what is the minimum sum assured for accident cover ?\"\n",
        ")"
      ],
      "metadata": {
        "id": "TCIbtikSAShs",
        "outputId": "3c361990-3c9a-42da-da83-e72ae530b608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TCIbtikSAShs",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: what is the minimum sum assured for accident cover ?\n",
            "=== Calling Function ===\n",
            "Calling function: tool_max-life-smart-term-insurence with args: {\"input\": \"minimum sum assured for accident cover\"}\n",
            "Added user message to memory: minimum sum assured for accident cover\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"input\":\"minimum sum assured for accident cover\"}\n",
            "Got output: The minimum sum assured for the accident cover is 100% of the Accident Cover Sum Assured, which will be payable as a lump sum in case the Life Insured dies due to an accident.\n",
            "========================\n",
            "\n",
            "Got output: The minimum sum assured for accident cover is 100% of the Accident Cover Sum Assured, which will be payable as a lump sum in case the Life Insured dies due to an accident.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: tool_hdfc-smart-term-insurence with args: {\"input\": \"minimum sum assured for accident cover\"}\n",
            "Added user message to memory: minimum sum assured for accident cover\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"input\":\"minimum sum assured for accident cover\"}\n",
            "Got output: ₹10,00,000\n",
            "========================\n",
            "\n",
            "Got output: The minimum sum assured for accident cover in HDFC Smart Term Insurance is ₹10,00,000.\n",
            "========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "d476c54b-98af-4d2a-8f17-4baa37d0d360",
      "metadata": {
        "id": "d476c54b-98af-4d2a-8f17-4baa37d0d360",
        "outputId": "8340ce16-6ea8-4279-96f4-40cde8c00b36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The minimum sum assured for accident cover is 100% of the Accident Cover Sum Assured in Max Life Smart Term Insurance, payable as a lump sum in case the Life Insured dies due to an accident. \n",
            "\n",
            "In HDFC Smart Term Insurance, the minimum sum assured for accident cover is ₹10,00,000.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# should use Houston agent -> vector tool\n",
        "response = top_agent.query(\n",
        "    \"what are different premium payment modes?\"\n",
        ")"
      ],
      "metadata": {
        "id": "5MYsnojcAxn_",
        "outputId": "0214d3c6-cc19-495d-d798-370e81c6513b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5MYsnojcAxn_",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: what are different premium payment modes?\n",
            "=== Calling Function ===\n",
            "Calling function: tool_hdfc-smart-term-insurence with args: {\"input\": \"premium payment modes\"}\n",
            "Added user message to memory: premium payment modes\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"input\":\"premium payment modes\"}\n",
            "Got output: Premium payment modes vary based on the frequency of premium payments.\n",
            "========================\n",
            "\n",
            "Got output: Premium payment modes for HDFC Smart Term Insurance vary based on the frequency of premium payments.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: tool_max-life-smart-term-insurence with args: {\"input\": \"premium payment modes\"}\n",
            "Added user message to memory: premium payment modes\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"input\":\"premium payment modes\"}\n",
            "Got output: Annual, Semi-Annual, Quarterly, Monthly premium payment modes.\n",
            "========================\n",
            "\n",
            "Got output: The premium payment modes for Max Life Smart Term Insurance include Annual, Semi-Annual, Quarterly, and Monthly payment options.\n",
            "========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "eZbjadp2AxVr",
        "outputId": "f7e166d5-e2cc-4bcb-c33a-6191f173250a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eZbjadp2AxVr",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The premium payment modes for HDFC Smart Term Insurance vary based on the frequency of premium payments. For Max Life Smart Term Insurance, the premium payment modes include Annual, Semi-Annual, Quarterly, and Monthly payment options.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# should use Houston agent -> vector tool\n",
        "response = top_agent.query(\n",
        "    \"what are the differenc between both the plans ?\"\n",
        ")"
      ],
      "metadata": {
        "id": "yoD3i4JCBOyS",
        "outputId": "e21b3653-f125-42ae-8088-dbc3d2777637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yoD3i4JCBOyS",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: what are the differenc between both the plans ?\n",
            "=== Calling Function ===\n",
            "Calling function: tool_hdfc-smart-term-insurence with args: {\"input\": \"differences\"}\n",
            "Added user message to memory: differences\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\":\"differences\"}\n",
            "Got output: The differences in the insurance plan variants include the type of protection offered, the percentage of return of premiums, and the additional benefits available. Each variant - Classic, Step-up, and Comprehensive - has unique features tailored to suit different protection needs and financial goals. The Classic variant provides protection with a return of premium, the Step-up variant offers higher return of premium, and the Comprehensive variant includes enhanced protection with the option for additional sum assured through Extra Protection. Additionally, the benefits payable on death or maturity vary between the variants based on the premiums paid and the policy terms chosen.\n",
            "========================\n",
            "\n",
            "Got output: The differences in the HDFC Smart Term Insurance plan variants include the type of protection offered, the percentage of return of premiums, and the additional benefits available. Each variant - Classic, Step-up, and Comprehensive - has unique features tailored to suit different protection needs and financial goals. The Classic variant provides protection with a return of premium, the Step-up variant offers a higher return of premium, and the Comprehensive variant includes enhanced protection with the option for additional sum assured through Extra Protection. Additionally, the benefits payable on death or maturity vary between the variants based on the premiums paid and the policy terms chosen.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: tool_max-life-smart-term-insurence with args: {\"input\": \"differences\"}\n",
            "Added user message to memory: differences\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\":\"differences\"}\n",
            "Got output: The differences in the Max Life Smart Term Plan include the choice of Death Benefit Variants, the option to enhance cover with changing needs through Life Stage Add-On Sum Assured, the availability of Return of Premium with the Premium Back option, the comprehensive protection offered with riders like Max Life Waiver of Premium Plus Rider and Accident Cover option, the Accelerated Critical Illness Benefit with options for accelerated payout and increasing benefit, the flexibility in choosing premium payment terms, and the longer coverage duration with the choice of desired Policy Term up to age 85 years.\n",
            "========================\n",
            "\n",
            "Got output: The Max Life Smart Term Plan offers various differences such as different Death Benefit Variants, Life Stage Add-On Sum Assured, Return of Premium with the Premium Back option, riders like Max Life Waiver of Premium Plus Rider and Accident Cover option, Accelerated Critical Illness Benefit, flexible premium payment terms, and longer coverage duration with the choice of desired Policy Term up to age 85 years.\n",
            "========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "ICljvaFiBOvK",
        "outputId": "f735906e-b67d-4344-c860-7a617bf9acfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ICljvaFiBOvK",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The differences between the HDFC Smart Term Insurance plan variants include the type of protection offered, the percentage of return of premiums, and the additional benefits available. Each variant - Classic, Step-up, and Comprehensive - has unique features tailored to suit different protection needs and financial goals. The Classic variant provides protection with a return of premium, the Step-up variant offers a higher return of premium, and the Comprehensive variant includes enhanced protection with the option for additional sum assured through Extra Protection. Additionally, the benefits payable on death or maturity vary between the variants based on the premiums paid and the policy terms chosen.\n",
            "\n",
            "On the other hand, the Max Life Smart Term Plan offers various differences such as different Death Benefit Variants, Life Stage Add-On Sum Assured, Return of Premium with the Premium Back option, riders like Max Life Waiver of Premium Plus Rider and Accident Cover option, Accelerated Critical Illness Benefit, flexible premium payment terms, and longer coverage duration with the choice of desired Policy Term up to age 85 years.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MqTnScwPBOrM"
      },
      "id": "MqTnScwPBOrM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_gRfI2RlBOoZ"
      },
      "id": "_gRfI2RlBOoZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIN8NPi7BOlD"
      },
      "id": "wIN8NPi7BOlD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbUmfpZaBOXn"
      },
      "id": "WbUmfpZaBOXn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_index_v2",
      "language": "python",
      "name": "llama_index_v2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}