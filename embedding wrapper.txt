from transformers import AutoTokenizer, AutoModel
import torch

class CustomEmbeddingModel:
    def __init__(self, model_name: str):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        
    def embed(self, texts):
        # Handle single string input or a list of texts
        if isinstance(texts, str):
            texts = [texts]
        
        # Tokenize the input texts
        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
        
        # Get the embeddings from the model
        with torch.no_grad():
            outputs = self.model(**inputs)
            embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token embedding
        
        return embeddings

# Example usage
model_name = "sentence-transformers/all-mpnet-base-v2"
embedding_model = CustomEmbeddingModel(model_name=model_name)

# Single query embedding
query_embedding = embedding_model.embed("Hello, world!")
print(query_embedding)

# Multiple texts embedding
texts_embeddings = embedding_model.embed(["Hello, world!", "Langchain is great for LLM-based applications."])
print(texts_embeddings)
