from deepeval.models import DeepEvalBaseLLM
from langchain_community.llms import Ollama  # Import the Ollama model

class CustomOllamaModel(DeepEvalBaseLLM):
    def __init__(self):
        # Initialize the Ollama model
        self.model = Ollama(model="gemma2")  # Replace with the desired Ollama model name
        self.tokenizer = None  # Ollama models don't require a separate tokenizer

    def load_model(self):
        return self.model

    def generate(self, prompt: str) -> str:
        model = self.load_model()
        
        # Generate text using the Ollama model
        response = model(prompt)  # Assuming `model` is callable and returns the response text

        return response

    async def a_generate(self, prompt: str) -> str:
        # Use the same synchronous generate method for now
        return self.generate(prompt)

    def get_model_name(self):
        return "Ollama-Gemma2"  # Replace with the appropriate Ollama model name

# Example usage
custom_llm = CustomOllamaModel()
print(custom_llm.generate("Write me a joke"))

from deepeval.metrics import AnswerRelevancyMetric

metric = AnswerRelevancyMetric(model=custom_llm)
# metric.measure(...)  # Use this with appropriate input for evaluation
---------------------

from deepeval.scorer import Scorer
from deepeval.metrics import BaseMetric
from deepeval.test_case import LLMTestCase

class RougeMetric(BaseMetric):
    def __init__(self, threshold: float = 0.5):
        self.threshold = threshold
        self.scorer = Scorer()  # Initialize the Scorer here
        self.success = False  # Initialize self.success here

    def measure(self, test_case: LLMTestCase):
        # Measure the Rouge score using the scorer object
        self.score = self.scorer.rouge_score(
            prediction=test_case.actual_output,
            target=test_case.expected_output,
            score_type="rouge1"
        )
        self.success = self.score >= self.threshold
        return self.score

    async def a_measure(self, test_case: LLMTestCase):
        return self.measure(test_case)

    def is_successful(self):
        return self.success

    @property
    def __name__(self):
        return "Rouge Metric"

# Example usage
test_case = LLMTestCase(input="What is AI?", actual_output="AI stands for Artificial Intelligence.", expected_output="AI is short for Artificial Intelligence.")
metric = RougeMetric()

metric.measure(test_case)
print(metric.is_successful())

